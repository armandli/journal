{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "import math\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import utils\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import ToPILImage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/Users/armandli/data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = '/Users/armandli/journal/models/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "use_mps = torch.backends.mps.is_built()\n",
    "if use_cuda:\n",
    "    device = torch.device('cuda')\n",
    "elif use_mps:\n",
    "    device = torch.device('cpu')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "cpu = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_batch_size = 256\n",
    "loader_args = {'batch_size' : default_batch_size, 'shuffle' : True}\n",
    "score_args = {'batch_size' : default_batch_size, 'shuffle' : False}\n",
    "if use_cuda:\n",
    "    loader_args.update({'pin_memory' : True})\n",
    "    score_args.update({'pin_memory' : True})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = datasets.MNIST(root=data_dir, train=True, transform=transforms.ToTensor(), download=True)\n",
    "evalset  = datasets.MNIST(root=data_dir, train=False, transform=transforms.ToTensor(), download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "trainset = datasets.CIFAR10(root=data_dir, train=True, transform=transforms.ToTensor(), download=True)\n",
    "evalset = datasets.CIFAR10(root=data_dir, train=True, transform=transforms.ToTensor(), download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 50000)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trainset), len(evalset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = utils.data.DataLoader(dataset=trainset, **loader_args)\n",
    "eval_loader = utils.data.DataLoader(dataset=evalset, **score_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Gate(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Gate, self).__init__()\n",
    "    def forward(self, x):\n",
    "        a, b = torch.chunk(x, 2, dim=1)\n",
    "        return a * F.sigmoid(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConcatELU(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConcatELU, self).__init__()\n",
    "    def forward(self, x):\n",
    "        #concat at channel dim\n",
    "        return F.elu(torch.cat([x, -x], dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WeightNormLinear2d(nn.Module):\n",
    "    def __init__(self, d_in, d_out):\n",
    "        super(WeightNormLinear2d, self).__init__()\n",
    "        self.layer = nn.utils.parametrizations.weight_norm(nn.Linear(d_in, d_out))\n",
    "        self.d_out = d_out\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.permute(0, 2, 3, 1)\n",
    "        shape = [int(d) for d in x.shape]\n",
    "        x = self.layer(x.contiguous().view(shape[0]*shape[1]*shape[2], shape[3]))\n",
    "        shape[-1] = self.d_out\n",
    "        x = x.view(shape).permute(0, 3, 1, 2)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WeightNormConv2d(nn.Module):\n",
    "    def __init__(self, in_c, out_c, kernel_size, stride=1, padding=0):\n",
    "        super(WeightNormConv2d, self).__init__()\n",
    "        self.layer = nn.utils.parametrizations.weight_norm(nn.Conv2d(in_c, out_c, kernel_size=kernel_size, stride=stride, padding=padding))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.layer(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DownShift(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DownShift, self).__init__()\n",
    "        #pad Left=0 Right=0 Up=1 Down=0\n",
    "        self.pad = nn.ZeroPad2d((0,0,1,0))\n",
    "    def forward(self, x):\n",
    "        shape = x.shape\n",
    "        x = x[:, :, :shape[2]-1, :]\n",
    "        x = self.pad(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RightShift(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(RightShift, self).__init__()\n",
    "        #pad Left=1 Right=0 Up=0 Down=0\n",
    "        self.pad = nn.ZeroPad2d((1,0,0,0))\n",
    "    def forward(self, x):\n",
    "        shape = x.shape\n",
    "        x = x[:, :, :, :shape[3]-1]\n",
    "        x = self.pad(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DownShiftConv2d(nn.Module):\n",
    "    def __init__(self, in_c, out_c, kernel_size=(2,3), stride=(1,1), shift_down=False):\n",
    "        super(DownShiftConv2d, self).__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.ZeroPad2d((int((kernel_size[1]-1)/2),int((kernel_size[1]-1)/2),kernel_size[0]-1,0)),\n",
    "            WeightNormConv2d(in_c, out_c, kernel_size, stride),\n",
    "        )\n",
    "        if shift_down:\n",
    "            self.shift_down = DownShift()\n",
    "        else:\n",
    "            self.shift_down = nn.Identity()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layers(x)\n",
    "        x = self.shift_down(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DownRightShiftConv2d(nn.Module):\n",
    "    def __init__(self, in_c, out_c, kernel_size=(2,2), stride=(1,1), shift_right=False):\n",
    "        super(DownRightShiftConv2d, self).__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.ZeroPad2d((kernel_size[1]-1, 0, kernel_size[0]-1, 0)),\n",
    "            WeightNormConv2d(in_c, out_c, kernel_size, stride),\n",
    "        )\n",
    "        if shift_right:\n",
    "            self.shift_right = RightShift()\n",
    "        else:\n",
    "            self.shift_right = nn.Identity()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.layers(x)\n",
    "        x = self.shift_right(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GatedResidualLayer(nn.Module):\n",
    "    def __init__(self, nc, conv, skip=0, p_dropout=0.5):\n",
    "        super(GatedResidualLayer, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            ConcatELU(),\n",
    "            conv(2*nc, nc),\n",
    "        )\n",
    "        self.layer2 = nn.Sequential(\n",
    "            ConcatELU(),\n",
    "            nn.Dropout2d(p_dropout),\n",
    "            conv(2*nc, 2*nc),\n",
    "            Gate(),\n",
    "        )\n",
    "        if skip > 0:\n",
    "            self.skip = nn.Sequential(\n",
    "                ConcatELU(),\n",
    "                WeightNormLinear2d(2*skip*nc, nc),\n",
    "            )\n",
    "        \n",
    "    def forward(self, x, a=None):\n",
    "        s = x\n",
    "        x = self.layer1(x)\n",
    "        if a is not None:\n",
    "            x += self.skip(a)\n",
    "        x = self.layer2(x)\n",
    "        return s + x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UpSample(nn.Module):\n",
    "    def __init__(self, nlayers, nchannel):\n",
    "        super(UpSample, self).__init__()\n",
    "        self.up_stream = nn.ModuleList([\n",
    "            GatedResidualLayer(nchannel, DownShiftConv2d, skip=0)\n",
    "            for _ in range(nlayers)\n",
    "        ])\n",
    "        self.upleft_stream = nn.ModuleList([\n",
    "            GatedResidualLayer(nchannel, DownRightShiftConv2d, skip=1)\n",
    "            for _ in range(nlayers)\n",
    "        ])\n",
    "        self.nlayers = nlayers\n",
    "    def forward(self, up, upleft):\n",
    "        ups, uplefts = [], []\n",
    "        for i in range(self.nlayers):\n",
    "            up = self.up_stream[i](up)\n",
    "            upleft = self.upleft_stream[i](upleft, a=up)\n",
    "            ups.append(up)\n",
    "            uplefts.append(upleft)\n",
    "        return ups, uplefts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DownSample(nn.Module):\n",
    "    def __init__(self, nlayer, nchannel):\n",
    "        super(DownSample, self).__init__()\n",
    "        self.up_stream = nn.ModuleList([\n",
    "            GatedResidualLayer(nchannel, DownShiftConv2d, skip=1)\n",
    "            for _ in range(nlayer)\n",
    "        ])\n",
    "        self.upleft_stream = nn.ModuleList([\n",
    "            GatedResidualLayer(nchannel, DownRightShiftConv2d, skip=2)\n",
    "            for _ in range(nlayer)\n",
    "        ])\n",
    "        self.nlayer = nlayer\n",
    "    \n",
    "    def forward(self, up, upleft, ups, uplefts):\n",
    "        for i in range(self.nlayer):\n",
    "            up = self.up_stream[i](up, a=ups.pop())\n",
    "            upleft = self.upleft_stream[i](upleft, a=torch.cat((up, uplefts.pop()), 1))\n",
    "        return up, upleft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WeightNormConvTransposed2d(nn.Module):\n",
    "    def __init__(self, in_c, out_c, kernel_size, stride, output_padding=1):\n",
    "        super(WeightNormConvTransposed2d, self).__init__()\n",
    "        self.layer = nn.utils.parametrizations.weight_norm(nn.ConvTranspose2d(in_c, out_c, kernel_size, stride, output_padding=output_padding))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.layer(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DownShiftDeconv2d(nn.Module):\n",
    "    def __init__(self, in_c, out_c, kernel_size=(2,3), stride=(2,2)):\n",
    "        super(DownShiftDeconv2d, self).__init__()\n",
    "        self.ks = kernel_size\n",
    "        self.layer = WeightNormConvTransposed2d(in_c, out_c, kernel_size, stride, output_padding=1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.layer(x)\n",
    "        s = x.shape\n",
    "        # correct the shape because TransposedConv2d would produce a few rows and columns bigger\n",
    "        x = x[:, :, :(s[2]-self.ks[0]+1), int((self.ks[1]-1)/2):(s[3]-int((self.ks[1]-1)/2))]\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DownRightShiftDeconv2d(nn.Module):\n",
    "    def __init__(self, in_c, out_c, kernel_size=(2,2), stride=(2,2)):\n",
    "        super(DownRightShiftDeconv2d, self).__init__()\n",
    "        self.ks = kernel_size\n",
    "        self.layer = WeightNormConvTransposed2d(in_c, out_c, kernel_size, stride, output_padding=1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.layer(x)\n",
    "        s = x.shape\n",
    "        # correct the shape because TransposedConv2d produces a few rows and columns bigger\n",
    "        x = x[:, :, :(s[2]-self.ks[0]+1):, :(s[3]-self.ks[1]+1)]\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PixelCNN(nn.Module):\n",
    "    def __init__(self, in_c, nresnet, nlayer, nchannel=80, nlogmix=10):\n",
    "        super(PixelCNN, self).__init__()\n",
    "        down_nlayer = [nresnet] + [nresnet+1 for _ in range(1, nlayer)]\n",
    "        self.down_layers = nn.ModuleList([\n",
    "            DownSample(down_nlayer[i], nchannel) for i in range(nlayer)\n",
    "        ])\n",
    "        self.up_layers = nn.ModuleList([\n",
    "            UpSample(nresnet, nchannel) for _ in range(nlayer)\n",
    "        ])\n",
    "        self.downsize_up_stream = nn.ModuleList([\n",
    "            DownShiftConv2d(nchannel, nchannel, stride=(2,2)) for _ in range((nlayer-1))\n",
    "        ])\n",
    "        self.downsize_upleft_stream = nn.ModuleList([\n",
    "            DownRightShiftConv2d(nchannel, nchannel, stride=(2,2)) for _ in range(nlayer-1)\n",
    "        ])\n",
    "        self.upsize_up_stream = nn.ModuleList([\n",
    "            DownShiftDeconv2d(nchannel, nchannel, stride=(2,2)) for _ in range(nlayer-1)\n",
    "        ])\n",
    "        self.upsize_upleft_stream = nn.ModuleList([\n",
    "            DownRightShiftDeconv2d(nchannel, nchannel, stride=(2,2)) for _ in range(nlayer-1)\n",
    "        ])\n",
    "        self.up_init = DownShiftConv2d(in_c+1, nchannel, kernel_size=(2,3), shift_down=True)\n",
    "        self.upleft_init = nn.ModuleList([\n",
    "            DownShiftConv2d(in_c+1, nchannel, kernel_size=(1,3), shift_down=True),\n",
    "            DownRightShiftConv2d(in_c+1, nchannel, kernel_size=(2,1), shift_right=True),\n",
    "        ])\n",
    "        self.out_layer = nn.Sequential(\n",
    "            nn.ELU(),\n",
    "            WeightNormLinear2d(nchannel, 10*nlogmix),\n",
    "        )\n",
    "        self.nlayer = nlayer\n",
    "    \n",
    "    def forward(self, x, device):\n",
    "        shape = x.shape\n",
    "        padding = torch.ones(shape[0], 1, shape[2], shape[3], device=device, requires_grad=False)\n",
    "        x = torch.cat((x, padding), 1)\n",
    "        \n",
    "        # UP PASS\n",
    "        ups = [self.up_init(x)]\n",
    "        uplefts = [self.upleft_init[0](x) + self.upleft_init[1](x)]\n",
    "        for i in range(self.nlayer):\n",
    "            up_out, upleft_out = self.up_layers[i](ups[-1], uplefts[-1])\n",
    "            ups.extend(up_out)\n",
    "            uplefts.extend(upleft_out)\n",
    "            if i < self.nlayer-1:\n",
    "                ups.append(self.downsize_up_stream[i](ups[-1]))\n",
    "                uplefts.append(self.downsize_upleft_stream[i](uplefts[-1]))\n",
    "\n",
    "        # DOWN PASS\n",
    "        up = ups.pop()\n",
    "        upleft = uplefts.pop()\n",
    "        for i in range(self.nlayer):\n",
    "            up, upleft = self.down_layers[i](up, upleft, ups, uplefts)\n",
    "            if i < self.nlayer-1:\n",
    "                up = self.upsize_up_stream[i](up)\n",
    "                upleft = self.upsize_upleft_stream[i](upleft)\n",
    "        \n",
    "        x = self.out_layer(upleft)\n",
    "        return x\n",
    "\n",
    "    def sample(self, batch_sz, img_shape, device):\n",
    "        x = torch.zeros(batch_sz, img_shape[0], img_shape[1], img_shape[2]).to(device)\n",
    "        shape = x.shape\n",
    "        padding = torch.ones(shape[0], 1, shape[2], shape[3], device=device, requires_grad=False)\n",
    "        x = torch.cat((x, padding), 1)\n",
    "        \n",
    "        # UP PASS\n",
    "        ups = [self.up_init(x)]\n",
    "        uplefts = [self.upleft_init[0](x) + self.upleft_init[1](x)]\n",
    "        for i in range(self.nlayer):\n",
    "            up_out, upleft_out = self.up_layers[i](ups[-1], uplefts[-1])\n",
    "            ups.extend(up_out)\n",
    "            uplefts.extend(upleft_out)\n",
    "            if i < self.nlayer-1:\n",
    "                ups.append(self.downsize_up_stream[i](ups[-1]))\n",
    "                uplefts.append(self.downsize_upleft_stream[i](uplefts[-1]))\n",
    "\n",
    "        # DOWN PASS\n",
    "        up = ups.pop()\n",
    "        upleft = uplefts.pop()\n",
    "        for i in range(self.nlayer):\n",
    "            up, upleft = self.down_layers[i](up, upleft, ups, uplefts)\n",
    "            if i < self.nlayer-1:\n",
    "                up = self.upsize_up_stream[i](up)\n",
    "                upleft = self.upsize_upleft_stream[i](upleft)\n",
    "        \n",
    "        x = self.out_layer(upleft)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PixelCNN(in_c=3, nresnset=1, nlayer=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 32, 32])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = trainset[0][0].unsqueeze(0)\n",
    "input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = model(input, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-0.0719, -0.0721, -0.0923,  ..., -0.1098, -0.1023, -0.0992],\n",
       "          [-0.1239, -0.0966, -0.1256,  ..., -0.1224, -0.1350, -0.1146],\n",
       "          [-0.1110, -0.0945, -0.1187,  ..., -0.1443, -0.1319, -0.1244],\n",
       "          ...,\n",
       "          [-0.1250, -0.0978, -0.1688,  ..., -0.1535, -0.1632, -0.1230],\n",
       "          [-0.1215, -0.1003, -0.1636,  ..., -0.1354, -0.1356, -0.1053],\n",
       "          [-0.1224, -0.0945, -0.1713,  ..., -0.1527, -0.1680, -0.1359]],\n",
       "\n",
       "         [[-0.0880, -0.1029, -0.1201,  ..., -0.1225, -0.1123, -0.1184],\n",
       "          [-0.0989, -0.1006, -0.1398,  ..., -0.1536, -0.1479, -0.1575],\n",
       "          [-0.0992, -0.1250, -0.1519,  ..., -0.1730, -0.1647, -0.1765],\n",
       "          ...,\n",
       "          [-0.0823, -0.1364, -0.1963,  ..., -0.1821, -0.2313, -0.1719],\n",
       "          [-0.0698, -0.1350, -0.1659,  ..., -0.1934, -0.1918, -0.1936],\n",
       "          [-0.0743, -0.1438, -0.1899,  ..., -0.2187, -0.2172, -0.1716]],\n",
       "\n",
       "         [[-0.0534, -0.0046, -0.0351,  ..., -0.0116, -0.0334, -0.0114],\n",
       "          [-0.0470, -0.0141, -0.0120,  ..., -0.0366, -0.0479, -0.0547],\n",
       "          [-0.0211,  0.0316,  0.0234,  ...,  0.0068, -0.0213, -0.0148],\n",
       "          ...,\n",
       "          [-0.0401, -0.0287, -0.0723,  ..., -0.0320, -0.0408, -0.0390],\n",
       "          [-0.0248, -0.0159, -0.0754,  ..., -0.0022, -0.0608, -0.0528],\n",
       "          [-0.0365, -0.0186, -0.0589,  ...,  0.0087, -0.0329, -0.0549]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-0.1002, -0.1278, -0.1212,  ..., -0.1057, -0.1160, -0.1120],\n",
       "          [-0.0594, -0.1307, -0.0823,  ..., -0.1035, -0.1040, -0.1073],\n",
       "          [-0.0747, -0.1633, -0.1249,  ..., -0.1352, -0.1511, -0.1331],\n",
       "          ...,\n",
       "          [-0.0757, -0.1879, -0.1678,  ..., -0.1491, -0.1507, -0.1191],\n",
       "          [-0.0711, -0.1788, -0.1581,  ..., -0.1104, -0.1261, -0.1134],\n",
       "          [-0.0698, -0.1834, -0.1678,  ..., -0.1376, -0.1577, -0.1375]],\n",
       "\n",
       "         [[ 0.0606,  0.0463,  0.0842,  ...,  0.0783,  0.0727,  0.0654],\n",
       "          [ 0.0683,  0.0639,  0.0908,  ...,  0.0812,  0.0705,  0.0755],\n",
       "          [ 0.0231,  0.0261,  0.0560,  ...,  0.0035,  0.0185,  0.0286],\n",
       "          ...,\n",
       "          [ 0.0011,  0.0130,  0.0068,  ...,  0.0205,  0.0023,  0.0643],\n",
       "          [-0.0103, -0.0056,  0.0061,  ...,  0.0017,  0.0585,  0.0464],\n",
       "          [-0.0076,  0.0061,  0.0014,  ...,  0.0537,  0.0424,  0.0807]],\n",
       "\n",
       "         [[ 0.0462,  0.0180,  0.0366,  ...,  0.0425,  0.0373,  0.0445],\n",
       "          [ 0.0554, -0.0011,  0.0242,  ...,  0.0403,  0.0204,  0.0248],\n",
       "          [ 0.0556, -0.0335,  0.0033,  ..., -0.0162, -0.0114, -0.0098],\n",
       "          ...,\n",
       "          [ 0.1138, -0.0373, -0.0311,  ...,  0.0115, -0.0176,  0.0224],\n",
       "          [ 0.1101, -0.0453, -0.0287,  ..., -0.0007, -0.0218,  0.0038],\n",
       "          [ 0.1076, -0.0291, -0.0193,  ...,  0.0300,  0.0044,  0.0133]]]],\n",
       "       grad_fn=<PermuteBackward0>)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 100, 32, 32])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_sum_exp(x):\n",
    "    \"\"\" numerically stable log_sum_exp implementation that prevents overflow \"\"\"\n",
    "    # TF ordering\n",
    "    axis  = len(x.size()) - 1\n",
    "    m, _  = torch.max(x, dim=axis)\n",
    "    m2, _ = torch.max(x, dim=axis, keepdim=True)\n",
    "    return m + torch.log(torch.sum(torch.exp(x - m2), dim=axis))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_prob_from_logits(x):\n",
    "    \"\"\" numerically stable log_softmax implementation that prevents overflow \"\"\"\n",
    "    # TF ordering\n",
    "    axis = len(x.size()) - 1\n",
    "    m, _ = torch.max(x, dim=axis, keepdim=True)\n",
    "    return x - m - torch.log(torch.sum(torch.exp(x - m), dim=axis, keepdim=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiscretizedMixLogisticLoss(nn.Module):\n",
    "    def __init__(self, nmix):\n",
    "        super(DiscretizedMixLogisticLoss, self).__init__()\n",
    "        self.nmix = nmix\n",
    "    \n",
    "    def log_sum_exp(self, x):\n",
    "        axis = len(x.shape)-1\n",
    "        m, _ = torch.max(x, dim=axis)\n",
    "        n, _ = torch.max(x, dim=axis, keepdim=True)\n",
    "        return m + torch.log(torch.sum(torch.exp(x-n), dim=axis))\n",
    "\n",
    "    def log_prob_from_logits(self, x):\n",
    "        axis = len(x.shape)-1\n",
    "        m, _ = torch.max(x, dim=axis, keepdim=True)\n",
    "        return x - m - torch.log(torch.sum(torch.exp(x-m), dim=axis, keepdim=True))\n",
    "    \n",
    "    def forward(self, target, prediction, device):\n",
    "        nmix = self.nmix\n",
    "        target = target.permute(0, 2, 3, 1)\n",
    "        prediction = prediction.permute(0, 2, 3, 1)\n",
    "        ts = list(target.shape)\n",
    "\n",
    "        # unpack prediction parameters\n",
    "        lp = prediction[:,:,:,:nmix]\n",
    "        prediction = prediction[:,:,:,nmix:].view(ts+[nmix*3]) # 3 for mean, scale, coeff\n",
    "        means = prediction[:,:,:,:,:nmix]\n",
    "        log_scales = torch.clamp(prediction[:,:,:,:,nmix:nmix*2], min=-7.)\n",
    "        coeffs = F.tanh(prediction[:,:,:,:,nmix*2:nmix*3])\n",
    "        target = target.unsqueeze(-1) + torch.zeros(ts+[nmix], requires_grad=False).to(device)\n",
    "        \n",
    "        m2 = (means[:,:,:,1,:]+coeffs[:,:,:,0,:]*target[:,:,:,0,:]).view(ts[0],ts[1],ts[2],1,nmix)\n",
    "        m3 = (means[:,:,:,2,:]+coeffs[:,:,:,1,:]*target[:,:,:,0,:]+coeffs[:,:,:,2,:]*target[:,:,:,1,:]).view(ts[0],ts[1],ts[2],1,nmix)\n",
    "        \n",
    "        centered_target = target - torch.cat((means[:,:,:,0,:].unsqueeze(3), m2, m3), dim=3)\n",
    "        inv_stdv  = torch.exp(-log_scales)\n",
    "        plus_in   = inv_stdv * (centered_target + 1./255.)\n",
    "        cdf_plus  = F.sigmoid(plus_in)\n",
    "        min_in    = inv_stdv * (centered_target - 1./255.)\n",
    "        cdf_minus = F.sigmoid(min_in)\n",
    "\n",
    "        log_cdf_plus          = plus_in - F.softplus(plus_in)\n",
    "        log_one_minus_cdf_min = -F.softplus(min_in)\n",
    "        cdf_delta             = cdf_plus - cdf_minus\n",
    "        log_pdf_mid = (inv_stdv*centered_target) - log_scales - 2.*F.softplus(inv_stdv*centered_target)\n",
    "\n",
    "        inner_inner_cond = (cdf_delta > 1e-5).float()\n",
    "        inner_inner_out  = inner_inner_cond * torch.log(torch.clamp(cdf_delta, min=1e-12)) + (1-inner_inner_cond)*(log_pdf_mid-math.log(127.5))\n",
    "        inner_cond       = (target > 0.999).float()\n",
    "        inner_out        = inner_cond*log_one_minus_cdf_min + (1.-inner_cond)*inner_inner_out\n",
    "        cond             = (target < -0.999).float()\n",
    "        log_probs        = cond*log_cdf_plus + (1.-cond)*inner_out\n",
    "        log_probs        = torch.sum(log_probs, dim=3) + self.log_prob_from_logits(lp)\n",
    "        return -torch.sum(self.log_sum_exp(log_probs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discretized_mix_logistic_loss(x, l, device):\n",
    "    \"\"\" log-likelihood for mixture of discretized logistics, assumes the data has been rescaled to [-1,1] interval \"\"\"\n",
    "    # Pytorch ordering\n",
    "    x = x.permute(0, 2, 3, 1)\n",
    "    l = l.permute(0, 2, 3, 1)\n",
    "    xs = [int(y) for y in x.size()]\n",
    "    ls = [int(y) for y in l.size()]\n",
    "   \n",
    "    # here and below: unpacking the params of the mixture of logistics\n",
    "    nr_mix = int(ls[-1] / 10)\n",
    "    #print(f\"gothere10 {nr_mix} {ls[-1]} {l.size()} {l.shape}\")\n",
    "    logit_probs = l[:, :, :, :nr_mix]\n",
    "    l = l[:, :, :, nr_mix:].contiguous().view(xs + [nr_mix * 3]) # 3 for mean, scale, coef\n",
    "    #print(f\"gothere11 {l.shape}\")\n",
    "    means = l[:, :, :, :, :nr_mix]\n",
    "    # log_scales = torch.max(l[:, :, :, :, nr_mix:2 * nr_mix], -7.)\n",
    "    log_scales = torch.clamp(l[:, :, :, :, nr_mix:2 * nr_mix], min=-7.)\n",
    "   \n",
    "    coeffs = F.tanh(l[:, :, :, :, 2 * nr_mix:3 * nr_mix])\n",
    "    # here and below: getting the means and adjusting them based on preceding\n",
    "    # sub-pixels\n",
    "    x = x.contiguous()\n",
    "    x = x.unsqueeze(-1) + Variable(torch.zeros(xs + [nr_mix]).to(device), requires_grad=False)\n",
    "    #print(f\"gothere12 new x {x.shape}\")\n",
    "    m2 = (means[:, :, :, 1, :] + \n",
    "          coeffs[:, :, :, 0, :] * x[:, :, :, 0, :]\n",
    "    ).view(xs[0], xs[1], xs[2], 1, nr_mix)\n",
    "\n",
    "    m3 = (means[:, :, :, 2, :] + \n",
    "          coeffs[:, :, :, 1, :] * x[:, :, :, 0, :] + \n",
    "          coeffs[:, :, :, 2, :] * x[:, :, :, 1, :]\n",
    "    ).view(xs[0], xs[1], xs[2], 1, nr_mix)\n",
    "\n",
    "    means = torch.cat((means[:, :, :, 0, :].unsqueeze(3), m2, m3), dim=3)\n",
    "    centered_x = x - means\n",
    "    inv_stdv = torch.exp(-log_scales)\n",
    "    plus_in = inv_stdv * (centered_x + 1. / 255.)\n",
    "    cdf_plus = F.sigmoid(plus_in)\n",
    "    min_in = inv_stdv * (centered_x - 1. / 255.)\n",
    "    cdf_min = F.sigmoid(min_in)\n",
    "    # log probability for edge case of 0 (before scaling)\n",
    "    log_cdf_plus = plus_in - F.softplus(plus_in)\n",
    "    # log probability for edge case of 255 (before scaling)\n",
    "    log_one_minus_cdf_min = -F.softplus(min_in)\n",
    "    cdf_delta = cdf_plus - cdf_min  # probability for all other cases\n",
    "    mid_in = inv_stdv * centered_x\n",
    "    # log probability in the center of the bin, to be used in extreme cases\n",
    "    # (not actually used in our code)\n",
    "    log_pdf_mid = mid_in - log_scales - 2. * F.softplus(mid_in)\n",
    "\n",
    "    # now select the right output: left edge case, right edge case, normal\n",
    "    # case, extremely low prob case (doesn't actually happen for us)\n",
    "\n",
    "    # this is what we are really doing, but using the robust version below for extreme cases in other applications and to avoid NaN issue with tf.select()\n",
    "    # log_probs = tf.select(x < -0.999, log_cdf_plus, tf.select(x > 0.999, log_one_minus_cdf_min, tf.log(cdf_delta)))\n",
    "\n",
    "    # robust version, that still works if probabilities are below 1e-5 (which never happens in our code)\n",
    "    # tensorflow backpropagates through tf.select() by multiplying with zero instead of selecting: this requires use to use some ugly tricks to avoid potential NaNs\n",
    "    # the 1e-12 in tf.maximum(cdf_delta, 1e-12) is never actually used as output, it's purely there to get around the tf.select() gradient issue\n",
    "    # if the probability on a sub-pixel is below 1e-5, we use an approximation\n",
    "    # based on the assumption that the log-density is constant in the bin of\n",
    "    # the observed sub-pixel value\n",
    "\n",
    "    inner_inner_cond = (cdf_delta > 1e-5).float()\n",
    "    inner_inner_out  = inner_inner_cond * torch.log(torch.clamp(cdf_delta, min=1e-12)) + (1. - inner_inner_cond) * (log_pdf_mid - np.log(127.5))\n",
    "    inner_cond       = (x > 0.999).float()\n",
    "    inner_out        = inner_cond * log_one_minus_cdf_min + (1. - inner_cond) * inner_inner_out\n",
    "    cond             = (x < -0.999).float()\n",
    "    log_probs        = cond * log_cdf_plus + (1. - cond) * inner_out\n",
    "    log_probs        = torch.sum(log_probs, dim=3) + log_prob_from_logits(logit_probs)\n",
    "    \n",
    "    return -torch.sum(log_sum_exp(log_probs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discretized_mix_logistic_loss_1d(x, l, device):\n",
    "    \"\"\" log-likelihood for mixture of discretized logistics, assumes the data has been rescaled to [-1,1] interval \"\"\"\n",
    "    # Pytorch ordering\n",
    "    x = x.permute(0, 2, 3, 1)\n",
    "    l = l.permute(0, 2, 3, 1)\n",
    "    xs = [int(y) for y in x.size()]\n",
    "    ls = [int(y) for y in l.size()]\n",
    "\n",
    "    # here and below: unpacking the params of the mixture of logistics\n",
    "    nr_mix = int(ls[-1] / 3)\n",
    "    logit_probs = l[:, :, :, :nr_mix]\n",
    "    l = l[:, :, :, nr_mix:].contiguous().view(xs + [nr_mix * 2]) # 2 for mean, scale\n",
    "    means = l[:, :, :, :, :nr_mix]\n",
    "    log_scales = torch.clamp(l[:, :, :, :, nr_mix:2 * nr_mix], min=-7.)\n",
    "    # here and below: getting the means and adjusting them based on preceding\n",
    "    # sub-pixels\n",
    "    x = x.contiguous()\n",
    "    x = x.unsqueeze(-1) + Variable(torch.zeros(xs + [nr_mix]).to(device), requires_grad=False)\n",
    "\n",
    "    # means = torch.cat((means[:, :, :, 0, :].unsqueeze(3), m2, m3), dim=3)\n",
    "    centered_x = x - means\n",
    "    inv_stdv = torch.exp(-log_scales)\n",
    "    plus_in = inv_stdv * (centered_x + 1. / 255.)\n",
    "    cdf_plus = F.sigmoid(plus_in)\n",
    "    min_in = inv_stdv * (centered_x - 1. / 255.)\n",
    "    cdf_min = F.sigmoid(min_in)\n",
    "    # log probability for edge case of 0 (before scaling)\n",
    "    log_cdf_plus = plus_in - F.softplus(plus_in)\n",
    "    # log probability for edge case of 255 (before scaling)\n",
    "    log_one_minus_cdf_min = -F.softplus(min_in)\n",
    "    cdf_delta = cdf_plus - cdf_min  # probability for all other cases\n",
    "    mid_in = inv_stdv * centered_x\n",
    "    # log probability in the center of the bin, to be used in extreme cases\n",
    "    # (not actually used in our code)\n",
    "    log_pdf_mid = mid_in - log_scales - 2. * F.softplus(mid_in)\n",
    "    \n",
    "    inner_inner_cond = (cdf_delta > 1e-5).float()\n",
    "    inner_inner_out  = inner_inner_cond*torch.log(torch.clamp(cdf_delta, min=1e-12)) + (1.-inner_inner_cond)*(log_pdf_mid - np.log(127.5))\n",
    "    inner_cond       = (x > 0.999).float()\n",
    "    inner_out        = inner_cond * log_one_minus_cdf_min + (1.-inner_cond)*inner_inner_out\n",
    "    cond             = (x < -0.999).float()\n",
    "    log_probs        = cond*log_cdf_plus + (1.-cond)*inner_out\n",
    "    log_probs        = torch.sum(log_probs, dim=3) + log_prob_from_logits(logit_probs)\n",
    "    \n",
    "    return -torch.sum(log_sum_exp(log_probs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Reporter(ABC):\n",
    "    @abstractmethod\n",
    "    def report(self, typ, **metric):\n",
    "        pass\n",
    "    @abstractmethod\n",
    "    def reset(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SReporter(Reporter):\n",
    "    def __init__(self):\n",
    "        self.log = []\n",
    "    def report(self, typ, **data):\n",
    "        self.log.append((typ, data))\n",
    "    def reset(self):\n",
    "        self.log.clear()\n",
    "    def loss(self, t):\n",
    "        losses = []\n",
    "        for (typ, data) in self.log:\n",
    "            if typ == t:\n",
    "                losses.append(data['loss'])\n",
    "        return losses\n",
    "    def loss(self, t, idx):\n",
    "        if idx >= 0:\n",
    "            count = 0\n",
    "            for (typ, data) in self.log:\n",
    "                if typ == t:\n",
    "                    if count == idx:\n",
    "                        return data['loss']\n",
    "                    count += 1\n",
    "        else:\n",
    "            count = -1\n",
    "            for (typ, data) in reversed(self.log):\n",
    "                if typ == t:\n",
    "                    if count == idx:\n",
    "                        return data['loss']\n",
    "                    count -= 1\n",
    "        return float(\"inf\")\n",
    "    def eval_loss(self):\n",
    "        return self.loss('eval')\n",
    "    def train_loss(self):\n",
    "        return self.loss('train')\n",
    "    def eval_loss(self, idx):\n",
    "        return self.loss('eval', idx)\n",
    "    def train_loss(self, idx):\n",
    "        return self.loss('train', idx)\n",
    "    def get_record(self, t, idx):\n",
    "        if idx >= 0:\n",
    "            count = 0\n",
    "            for (typ, data) in self.log:\n",
    "                if typ == t:\n",
    "                    if count == idx:\n",
    "                        return data\n",
    "                    count += 1\n",
    "        else:\n",
    "            count = -1\n",
    "            for (typ, data) in reversed(self.log):\n",
    "                if typ == t:\n",
    "                    if count == idx:\n",
    "                        return data\n",
    "                    count -= 1\n",
    "        return dict()\n",
    "    def eval_record(self, idx):\n",
    "        return self.get_record('eval', idx)\n",
    "    def train_record(self, idx):\n",
    "        return self.get_record('train', idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, device, loader, optimizer, loss, epoch, reporter):\n",
    "    model.train()\n",
    "    total_loss = 0.\n",
    "    for x, _ in loader:\n",
    "        optimizer.zero_grad()\n",
    "        x = x.to(device)\n",
    "        x_h = model(x, device)\n",
    "        l = loss(x, x_h, device)\n",
    "        l.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += l.item()\n",
    "        print(f\"Epoch {epoch}: {l.item()}\")\n",
    "    total_loss /= float(len(loader.dataset))\n",
    "    reporter.report(typ='train', loss=total_loss)\n",
    "    print(f\"Train Loss: {total_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, device, loader, loss, train_epoch, reporter):\n",
    "    model.eval()\n",
    "    total_loss = 0.\n",
    "    with torch.no_grad():\n",
    "        for x, _ in loader:\n",
    "            x = x.to(device)\n",
    "            x_h = model(x, device)\n",
    "            total_loss += loss(x, x_h, device)\n",
    "    total_loss /= float(len(loader.dataset))\n",
    "    reporter.report(typ='eval', loss=total_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_validate(model, device, train_loader, eval_loader, optimizer, scheduler, loss, total_epoch, patience, patience_decay, reporter):\n",
    "    validation_loss = float(\"inf\")\n",
    "    patience_count = patience\n",
    "    patience = int(patience * patience_decay)\n",
    "    reset_patience = False\n",
    "    for epoch in range(total_epoch):\n",
    "        train(model, device, train_loader, optimizer, loss, epoch, reporter)\n",
    "        validate(model, device, eval_loader, loss, epoch, reporter)\n",
    "        new_validation_loss = reporter.eval_loss(-1)\n",
    "        print(f\"Epoch {epoch} Validation Loss: {new_validation_loss}\")\n",
    "        scheduler.step(new_validation_loss)\n",
    "        if new_validation_loss < validation_loss:\n",
    "            validation_loss = new_validation_loss\n",
    "            patience_count = patience\n",
    "            if reset_patience:\n",
    "                patience = int(patience * patience_decay)\n",
    "                reset_patience = False\n",
    "        else:\n",
    "            validation_loss = new_validation_loss\n",
    "            patience_count -= 1\n",
    "            reset_patience = True\n",
    "            if patience_count <= 0:\n",
    "                print(f\"Improvement stopped. Validation Loss: {validation_loss}\")\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PixelCNN(in_c=3, nresnset=1, nlayer=2)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.0001\n",
    "total_epochs = 10\n",
    "patience = 8\n",
    "patience_decay = 0.9\n",
    "optimizer = optim.Adam(model.parameters(recurse=True), lr=learning_rate)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=patience/4, threshold=0.00001)\n",
    "loss      = discretized_mix_logistic_loss\n",
    "#loss      = discretized_mix_logistic_loss_1d\n",
    "reporter  = SReporter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 4919482.0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/armandli/journal/diffusion/pixelcnn3.ipynb Cell 44\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/armandli/journal/diffusion/pixelcnn3.ipynb#X61sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m train_validate(model, device, train_loader, eval_loader, optimizer, scheduler, loss, total_epochs, patience, patience_decay, reporter)\n",
      "\u001b[1;32m/Users/armandli/journal/diffusion/pixelcnn3.ipynb Cell 44\u001b[0m line \u001b[0;36m7\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/armandli/journal/diffusion/pixelcnn3.ipynb#X61sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m reset_patience \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/armandli/journal/diffusion/pixelcnn3.ipynb#X61sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(total_epoch):\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/armandli/journal/diffusion/pixelcnn3.ipynb#X61sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     train(model, device, train_loader, optimizer, loss, epoch, reporter)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/armandli/journal/diffusion/pixelcnn3.ipynb#X61sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     validate(model, device, eval_loader, loss, epoch, reporter)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/armandli/journal/diffusion/pixelcnn3.ipynb#X61sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     new_validation_loss \u001b[39m=\u001b[39m reporter\u001b[39m.\u001b[39meval_loss(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n",
      "\u001b[1;32m/Users/armandli/journal/diffusion/pixelcnn3.ipynb Cell 44\u001b[0m line \u001b[0;36m7\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/armandli/journal/diffusion/pixelcnn3.ipynb#X61sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/armandli/journal/diffusion/pixelcnn3.ipynb#X61sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m x \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/armandli/journal/diffusion/pixelcnn3.ipynb#X61sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m x_h \u001b[39m=\u001b[39m model(x, device)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/armandli/journal/diffusion/pixelcnn3.ipynb#X61sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m l \u001b[39m=\u001b[39m loss(x, x_h, device)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/armandli/journal/diffusion/pixelcnn3.ipynb#X61sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m l\u001b[39m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/journal/env/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/journal/env/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[1;32m/Users/armandli/journal/diffusion/pixelcnn3.ipynb Cell 44\u001b[0m line \u001b[0;36m5\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/armandli/journal/diffusion/pixelcnn3.ipynb#X61sZmlsZQ%3D%3D?line=52'>53</a>\u001b[0m upleft \u001b[39m=\u001b[39m uplefts\u001b[39m.\u001b[39mpop()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/armandli/journal/diffusion/pixelcnn3.ipynb#X61sZmlsZQ%3D%3D?line=53'>54</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnlayer):\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/armandli/journal/diffusion/pixelcnn3.ipynb#X61sZmlsZQ%3D%3D?line=54'>55</a>\u001b[0m     up, upleft \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdown_layers[i](up, upleft, ups, uplefts)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/armandli/journal/diffusion/pixelcnn3.ipynb#X61sZmlsZQ%3D%3D?line=55'>56</a>\u001b[0m     \u001b[39mif\u001b[39;00m i \u001b[39m<\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnlayer\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m:\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/armandli/journal/diffusion/pixelcnn3.ipynb#X61sZmlsZQ%3D%3D?line=56'>57</a>\u001b[0m         up \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mupsize_up_stream[i](up)\n",
      "File \u001b[0;32m~/journal/env/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/journal/env/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[1;32m/Users/armandli/journal/diffusion/pixelcnn3.ipynb Cell 44\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/armandli/journal/diffusion/pixelcnn3.ipynb#X61sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnlayer):\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/armandli/journal/diffusion/pixelcnn3.ipynb#X61sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m     up \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mup_stream[i](up, a\u001b[39m=\u001b[39mups\u001b[39m.\u001b[39mpop())\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/armandli/journal/diffusion/pixelcnn3.ipynb#X61sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m     upleft \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mupleft_stream[i](upleft, a\u001b[39m=\u001b[39;49mtorch\u001b[39m.\u001b[39;49mcat((up, uplefts\u001b[39m.\u001b[39;49mpop()), \u001b[39m1\u001b[39;49m))\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/armandli/journal/diffusion/pixelcnn3.ipynb#X61sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m \u001b[39mreturn\u001b[39;00m up, upleft\n",
      "File \u001b[0;32m~/journal/env/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/journal/env/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[1;32m/Users/armandli/journal/diffusion/pixelcnn3.ipynb Cell 44\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/armandli/journal/diffusion/pixelcnn3.ipynb#X61sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m \u001b[39mif\u001b[39;00m a \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/armandli/journal/diffusion/pixelcnn3.ipynb#X61sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m     x \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mskip(a)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/armandli/journal/diffusion/pixelcnn3.ipynb#X61sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlayer2(x)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/armandli/journal/diffusion/pixelcnn3.ipynb#X61sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m \u001b[39mreturn\u001b[39;00m s \u001b[39m+\u001b[39m x\n",
      "File \u001b[0;32m~/journal/env/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/journal/env/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/journal/env/lib/python3.11/site-packages/torch/nn/modules/container.py:215\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    214\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> 215\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    216\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[0;32m~/journal/env/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/journal/env/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[1;32m/Users/armandli/journal/diffusion/pixelcnn3.ipynb Cell 44\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/armandli/journal/diffusion/pixelcnn3.ipynb#X61sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/armandli/journal/diffusion/pixelcnn3.ipynb#X61sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlayers(x)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/armandli/journal/diffusion/pixelcnn3.ipynb#X61sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mshift_right(x)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/armandli/journal/diffusion/pixelcnn3.ipynb#X61sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/journal/env/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/journal/env/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/journal/env/lib/python3.11/site-packages/torch/nn/modules/container.py:215\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    214\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> 215\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    216\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[0;32m~/journal/env/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/journal/env/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[1;32m/Users/armandli/journal/diffusion/pixelcnn3.ipynb Cell 44\u001b[0m line \u001b[0;36m7\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/armandli/journal/diffusion/pixelcnn3.ipynb#X61sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/armandli/journal/diffusion/pixelcnn3.ipynb#X61sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlayer(x)\n",
      "File \u001b[0;32m~/journal/env/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/journal/env/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/journal/env/lib/python3.11/site-packages/torch/nn/modules/conv.py:460\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    459\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 460\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_conv_forward(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "File \u001b[0;32m~/journal/env/lib/python3.11/site-packages/torch/nn/modules/conv.py:456\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mzeros\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m    453\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39mconv2d(F\u001b[39m.\u001b[39mpad(\u001b[39minput\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode),\n\u001b[1;32m    454\u001b[0m                     weight, bias, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstride,\n\u001b[1;32m    455\u001b[0m                     _pair(\u001b[39m0\u001b[39m), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdilation, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgroups)\n\u001b[0;32m--> 456\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mconv2d(\u001b[39minput\u001b[39;49m, weight, bias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstride,\n\u001b[1;32m    457\u001b[0m                 \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdilation, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgroups)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_validate(model, device, train_loader, eval_loader, optimizer, scheduler, loss, total_epochs, patience, patience_decay, reporter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "testing loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PixelCNN(in_c=3, nresnet=1, nlayer=1).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = DiscretizedMixLogisticLoss(nmix=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 32, 32])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = trainset[0][0]\n",
    "x = x.unsqueeze(0)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = model(x, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19494.66796875\n"
     ]
    }
   ],
   "source": [
    "l = loss(x, y, device)\n",
    "print(l.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19494.66796875\n"
     ]
    }
   ],
   "source": [
    "l = discretized_mix_logistic_loss(x, y, device)\n",
    "print(l.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = model_dir + 'pixelcnn_v1.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PixelCNN(in_c=3, nresnet=1, nlayer=2)\n",
    "model.load_state_dict(torch.load(filepath, map_location=device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MixLogisticToColorChannel(nn.Module):\n",
    "    def __init__(self, nmix):\n",
    "        super(MixLogisticToColorChannel, self).__init__()\n",
    "        self.nmix = nmix\n",
    "    \n",
    "    def forward(self, x, device):\n",
    "        nmix = self.nmix\n",
    "        x = x.permute(0, 2, 3, 1)\n",
    "        xs = list(x.shape[:-1]) + [3] #TODO: 3 is channel number\n",
    "        # unpack parameters\n",
    "        p = x[:,:,:,:nmix]\n",
    "        x = x[:,:,:,nmix:].view(xs + [nmix*3])\n",
    "        # sample mixture indicator from softmax\n",
    "        temp = torch.FloatTensor(p.shape).to(device)\n",
    "        temp.uniform_(1e-5, 1.-1e-5)\n",
    "        temp = p - torch.log(-torch.log(temp))\n",
    "        _, argmax = temp.max(dim=3)\n",
    "        \n",
    "        one_hot = torch.FloatTensor(argmax.size()+(nmix,)).zero_().to(device)\n",
    "        one_hot.scatter_(len(argmax.size()), argmax.unsqueeze(-1), 1.)\n",
    "        sel = one_hot.view(xs[:-1]+[1, nmix])\n",
    "        #select logistic parameter\n",
    "        means = torch.sum(x[:,:,:,:,:nmix] * sel, dim=4)\n",
    "        log_scales = torch.clamp(torch.sum(x[:,:,:,:,nmix:2*nmix]*sel, dim=4), min=-7.)\n",
    "        coeffs = torch.sum(F.tanh(x[:,:,:,:,2*nmix:3*nmix]*sel), dim=4)\n",
    "        # sample from logistic & clip to interval\n",
    "        # don't actually round to nearest 8 bit value when sampling\n",
    "        u = torch.FloatTensor(means.shape).to(device)\n",
    "        u.uniform_(1e-5, 1.-1e-5)\n",
    "        x = means + torch.exp(log_scales)*(torch.log(u)-torch.log(1.-u))\n",
    "        x0 = torch.clamp(x[:,:,:,0], min=-1., max=1.)\n",
    "        x1 = torch.clamp(x[:,:,:,1]+coeffs[:,:,:,0]*x0, min=-1., max=1.)\n",
    "        x2 = torch.clamp(x[:,:,:,2]+coeffs[:,:,:,1]*x0+coeffs[:,:,:,2]*x1, min=-1., max=1.)\n",
    "        x = torch.cat([x0.view(xs[:-1]+[1]), x1.view(xs[:-1]+[1]), x2.view(xs[:-1]+[1])], dim=3)\n",
    "        x = x.permute(0, 3, 1, 2)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_one_hot(tensor, n, device, fill_with=1.):\n",
    "    # we perform one hot encore with respect to the last axis\n",
    "    one_hot = torch.FloatTensor(tensor.size() + (n,)).zero_().to(device)\n",
    "    one_hot.scatter_(len(tensor.size()), tensor.unsqueeze(-1), fill_with)\n",
    "    return one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_from_discretized_mix_logistic(l, nr_mix, device):\n",
    "    # Pytorch ordering\n",
    "    l = l.permute(0, 2, 3, 1)\n",
    "    ls = [int(y) for y in l.size()]\n",
    "    xs = ls[:-1] + [3]\n",
    "\n",
    "    # unpack parameters\n",
    "    logit_probs = l[:, :, :, :nr_mix]\n",
    "    l = l[:, :, :, nr_mix:].contiguous().view(xs + [nr_mix * 3])\n",
    "    print(f\"gothere10 l {l.shape} logit_probs {logit_probs.shape}\")\n",
    "    # sample mixture indicator from softmax\n",
    "    temp = torch.FloatTensor(logit_probs.size()).to(device)\n",
    "    temp.uniform_(1e-5, 1. - 1e-5)\n",
    "    temp = logit_probs.data - torch.log(- torch.log(temp))\n",
    "    _, argmax = temp.max(dim=3)\n",
    "    print(f\"gothere100 temp {temp.shape}\")\n",
    "   \n",
    "    one_hot = to_one_hot(argmax, nr_mix, device)\n",
    "    sel = one_hot.view(xs[:-1] + [1, nr_mix])\n",
    "    # select logistic parameters\n",
    "    means = torch.sum(l[:, :, :, :, :nr_mix] * sel, dim=4)\n",
    "    log_scales = torch.clamp(torch.sum(\n",
    "        l[:, :, :, :, nr_mix:2 * nr_mix] * sel, dim=4), min=-7.)\n",
    "    coeffs = torch.sum(F.tanh(\n",
    "        l[:, :, :, :, 2 * nr_mix:3 * nr_mix]) * sel, dim=4)\n",
    "    print(f\"gothere11 means {means.shape} log_scales {log_scales.shape} coeffs {coeffs.shape}\")\n",
    "    # sample from logistic & clip to interval\n",
    "    # we don't actually round to the nearest 8bit value when sampling\n",
    "    u = torch.FloatTensor(means.size()).to(device)\n",
    "    u.uniform_(1e-5, 1. - 1e-5)\n",
    "    x = means + torch.exp(log_scales) * (torch.log(u) - torch.log(1. - u))\n",
    "    x0 = torch.clamp(torch.clamp(x[:, :, :, 0], min=-1.), max=1.)\n",
    "    x1 = torch.clamp(torch.clamp(\n",
    "       x[:, :, :, 1] + coeffs[:, :, :, 0] * x0, min=-1.), max=1.)\n",
    "    x2 = torch.clamp(torch.clamp(\n",
    "       x[:, :, :, 2] + coeffs[:, :, :, 1] * x0 + coeffs[:, :, :, 2] * x1, min=-1.), max=1.)\n",
    "    print(f\"gothere12 x {x.shape} x0 {x0.shape} x1 {x1.shape} x2 {x2.shape}\")\n",
    "\n",
    "    out = torch.cat([x0.view(xs[:-1] + [1]), x1.view(xs[:-1] + [1]), x2.view(xs[:-1] + [1])], dim=3)\n",
    "    # put back in Pytorch ordering\n",
    "    out = out.permute(0, 3, 1, 2)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PixelCNN(in_c=3, nresnet=1, nlayer=2)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 32, 32])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = trainset[0][0].unsqueeze(0)\n",
    "input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 100, 32, 32])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = model(input, device)\n",
    "out.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gothere10 l torch.Size([1, 32, 32, 3, 30]) logit_probs torch.Size([1, 32, 32, 10])\n",
      "gothere100 temp torch.Size([1, 32, 32, 10])\n",
      "gothere11 means torch.Size([1, 32, 32, 3]) log_scales torch.Size([1, 32, 32, 3]) coeffs torch.Size([1, 32, 32, 3])\n",
      "gothere12 x torch.Size([1, 32, 32, 3]) x0 torch.Size([1, 32, 32]) x1 torch.Size([1, 32, 32]) x2 torch.Size([1, 32, 32])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 32, 32])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = sample_from_discretized_mix_logistic(out, 10, device)\n",
    "s = s.squeeze(0)\n",
    "s.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 32, 32])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = MixLogisticToColorChannel(10)\n",
    "s = m(out, device)\n",
    "s = s.squeeze(0)\n",
    "s.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_img = ToPILImage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=32x32>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_img(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
