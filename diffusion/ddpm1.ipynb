{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "import math\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import utils\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import ToPILImage\n",
    "from IPython.display import Image"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### diffusion model example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/Users/armandli/data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_img = ToPILImage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "use_mps = torch.backends.mps.is_built()\n",
    "if use_cuda:\n",
    "    device = torch.device('cuda')\n",
    "elif use_mps:\n",
    "    #mps has bugs that cannot handle ConvTranspose2d, reverting to cpu\n",
    "    #device = torch.device('mps')\n",
    "    device = torch.device('cpu')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "cpu = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_batch_size = 256\n",
    "loader_args = {'batch_size' : default_batch_size, 'shuffle' : True}\n",
    "score_args = {'batch_size' : default_batch_size, 'shuffle' : False}\n",
    "if use_cuda:\n",
    "    loader_args.update({'pin_memory' : True})\n",
    "    score_args.update({'pin_memory' : True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Reporter(ABC):\n",
    "    @abstractmethod\n",
    "    def report(self, typ, **metric):\n",
    "        pass\n",
    "    @abstractmethod\n",
    "    def reset(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SReporter(Reporter):\n",
    "    def __init__(self):\n",
    "        self.log = []\n",
    "    def report(self, typ, **data):\n",
    "        self.log.append((typ, data))\n",
    "    def reset(self):\n",
    "        self.log.clear()\n",
    "    def loss(self, t):\n",
    "        losses = []\n",
    "        for (typ, data) in self.log:\n",
    "            if typ == t:\n",
    "                losses.append(data['loss'])\n",
    "        return losses\n",
    "    def loss(self, t, idx):\n",
    "        if idx >= 0:\n",
    "            count = 0\n",
    "            for (typ, data) in self.log:\n",
    "                if typ == t:\n",
    "                    if count == idx:\n",
    "                        return data['loss']\n",
    "                    count += 1\n",
    "        else:\n",
    "            count = -1\n",
    "            for (typ, data) in reversed(self.log):\n",
    "                if typ == t:\n",
    "                    if count == idx:\n",
    "                        return data['loss']\n",
    "                    count -= 1\n",
    "        return float(\"inf\")\n",
    "    def eval_loss(self):\n",
    "        return self.loss('eval')\n",
    "    def train_loss(self):\n",
    "        return self.loss('train')\n",
    "    def eval_loss(self, idx):\n",
    "        return self.loss('eval', idx)\n",
    "    def train_loss(self, idx):\n",
    "        return self.loss('train', idx)\n",
    "    def get_record(self, t, idx):\n",
    "        if idx >= 0:\n",
    "            count = 0\n",
    "            for (typ, data) in self.log:\n",
    "                if typ == t:\n",
    "                    if count == idx:\n",
    "                        return data\n",
    "                    count += 1\n",
    "        else:\n",
    "            count = -1\n",
    "            for (typ, data) in reversed(self.log):\n",
    "                if typ == t:\n",
    "                    if count == idx:\n",
    "                        return data\n",
    "                    count -= 1\n",
    "        return dict()\n",
    "    def eval_record(self, idx):\n",
    "        return self.get_record('eval', idx)\n",
    "    def train_record(self, idx):\n",
    "        return self.get_record('train', idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeEmbeddingV1(nn.Module):\n",
    "    def __init__(self, cdim):\n",
    "        super(TimeEmbeddingV1, self).__init__()\n",
    "        self.cdim = cdim\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(self.cdim//4, self.cdim),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(self.cdim, self.cdim),\n",
    "        )\n",
    "    \n",
    "    def forward(self, t):\n",
    "        half_dim = self.cdim // 8\n",
    "        emb = math.log(10_000) / (half_dim-1)\n",
    "        emb = torch.exp(torch.arange(half_dim, device=t.device) * -emb)\n",
    "        emb = t[:,None] * emb[None,:]\n",
    "        emb = torch.cat((emb.sin(), emb.cos()), dim=1)\n",
    "        emb = self.layers(emb)\n",
    "        return emb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlockV1(nn.Module):\n",
    "    def __init__(self, cdim_in, cdim_out, tdim, gdim=32, dropout=0.1):\n",
    "        super(ResidualBlockV1, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.GroupNorm(gdim, cdim_in),\n",
    "            nn.SiLU(),\n",
    "            nn.Conv2d(cdim_in, cdim_out, kernel_size=(3,3), padding=(1,1)),\n",
    "        )\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.GroupNorm(gdim, cdim_out),\n",
    "            nn.SiLU(),\n",
    "            nn.Dropout(p=dropout),\n",
    "            nn.Conv2d(cdim_out, cdim_out, kernel_size=(3,3), padding=(1,1)),\n",
    "        )\n",
    "        self.time_layer = nn.Sequential(\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(tdim, cdim_out),\n",
    "        )\n",
    "        if cdim_in != cdim_out:\n",
    "            self.skip = nn.Conv2d(cdim_in, cdim_out, kernel_size=(1,1))\n",
    "        else:\n",
    "            self.skip = nn.Identity()\n",
    "    \n",
    "    def forward(self, x, t):\n",
    "        h = self.layer1(x)\n",
    "        h += self.time_layer(t)[:,:,None,None] #TODO: understand this\n",
    "        h = self.layer2(h)\n",
    "        return h + self.skip(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UpSampleV1(nn.Module):\n",
    "    def __init__(self, cdim):\n",
    "        super(UpSampleV1, self).__init__()\n",
    "        self.layer = nn.ConvTranspose2d(cdim, cdim, (4, 4), (2,2), (1,1))\n",
    "    \n",
    "    def forward(self, x, t):\n",
    "        return self.layer(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DownSampleV1(nn.Module):\n",
    "    def __init__(self, cdim):\n",
    "        super(DownSampleV1, self).__init__()\n",
    "        self.layer = nn.Conv2d(cdim, cdim, (3,3),(2,2),(1,1))\n",
    "    \n",
    "    def forward(self, x, t):\n",
    "        return self.layer(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DDPMV1(nn.Module):\n",
    "    def __init__(self, cdim_in=3, cdim=64, cmults=(1,2,2,4), n_blocks=2):\n",
    "        super(DDPMV1, self).__init__()\n",
    "        n = len(cmults)\n",
    "        self.time_emb = TimeEmbeddingV1(cdim*4)\n",
    "        self.image_proj = nn.Conv2d(cdim_in, cdim, kernel_size=(3,3), padding=(1,1))\n",
    "        down = []\n",
    "        out_channels = in_channels = cdim\n",
    "        for i in range(n):\n",
    "            out_channels = in_channels * cmults[i]\n",
    "            for _ in range(n_blocks):\n",
    "                down.append(ResidualBlockV1(in_channels, out_channels, cdim*4))\n",
    "                in_channels = out_channels\n",
    "            down.append(DownSampleV1(in_channels))\n",
    "        self.down = nn.ModuleList(down)\n",
    "        self.middle = ResidualBlockV1(out_channels, out_channels, cdim*4)\n",
    "        up = []\n",
    "        in_channels = out_channels\n",
    "        for i in reversed(range(n)):\n",
    "            up.append(UpSampleV1(in_channels))\n",
    "            out_channels = in_channels // cmults[i]\n",
    "            up.append(ResidualBlockV1(in_channels+out_channels*cmults[i], out_channels, cdim*4))\n",
    "            for _ in range(1, n_blocks):\n",
    "                up.append(ResidualBlockV1(out_channels, out_channels, cdim*4))\n",
    "            in_channels = out_channels\n",
    "        self.up = nn.ModuleList(up)\n",
    "        self.final = nn.Sequential(\n",
    "            nn.GroupNorm(8, cdim),\n",
    "            nn.SiLU(),\n",
    "            nn.Conv2d(in_channels, cdim_in, kernel_size=(3,3), padding=(1,1)),\n",
    "        )\n",
    "\n",
    "    def forward(self, x, t):\n",
    "        t = self.time_emb(t)\n",
    "        x = self.image_proj(x)\n",
    "        h = []\n",
    "        for m in self.down:\n",
    "            if isinstance(m, DownSampleV1):\n",
    "                h.append(x)\n",
    "            x = m(x, t)\n",
    "        x = self.middle(x, t)\n",
    "        is_first = False\n",
    "        for m in self.up:\n",
    "            if isinstance(m, UpSampleV1):\n",
    "                x = m(x, t)\n",
    "                is_first = True\n",
    "            else:\n",
    "                if is_first:\n",
    "                    s = h.pop()\n",
    "                    x = torch.cat((x, s), dim=1)\n",
    "                    is_first = False\n",
    "                x = m(x, t)\n",
    "        return self.final(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "### datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = datasets.MNIST(root=data_dir, transform=transforms.ToTensor(), download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "dataset = datasets.CIFAR10(root=data_dir, transform=transforms.ToTensor(), download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50000"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 32, 32])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shape = dataset[0][0].unsqueeze(0).shape\n",
    "shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = utils.data.DataLoader(dataset, **loader_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DDPMV1(cdim_in=3, cdim=32, cmults=(1,2), n_blocks=1)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = 1024\n",
    "learning_rate = 0.0001\n",
    "total_epochs = 2\n",
    "optimizer = optim.Adam(model.parameters(recurse=True), lr=learning_rate)\n",
    "loss = nn.MSELoss()\n",
    "reporter = SReporter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta = torch.linspace(0.0001, 0.02, T)\n",
    "alpha = 1. - beta\n",
    "alpha_bar = torch.cumprod(alpha, dim=0).to(device)\n",
    "sigma2 = beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def q_xt_x0(x0, t, alpha_bar):\n",
    "    mean = alpha_bar.gather(-1, t).reshape(-1, 1, 1, 1) ** 0.5 * x0\n",
    "    var = 1 - alpha_bar.gather(-1, t).reshape(-1, 1, 1, 1)\n",
    "    return mean, var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def q_sample(x0, t, alpha_bar, eps=None):\n",
    "    if eps is None:\n",
    "        eps = torch.randn_like(x0)\n",
    "    mean, var = q_xt_x0(x0, t, alpha_bar)\n",
    "    return mean + (var ** 0.5) * eps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def p_sample(xt, eps_theta, device, t, alpha_bars, alphas, sigma2s):\n",
    "    noise = torch.randn(xt.shape, device=device) if t != 0 else torch.zeros(xt.shape)\n",
    "    alpha_bar = alpha_bars.gather(-1, t)\n",
    "    alpha = alphas.gather(-1, t)\n",
    "    eps_coef = (1. - alpha) / (1 - alpha_bar) ** 0.5\n",
    "    var = sigma2s.gather(-1, t)\n",
    "    mean = 1 / (alpha ** 0.5) * (xt - eps_coef * eps_theta)\n",
    "    return mean + (var ** 0.5) * noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def diffusion_train(model, device, loader, optimizer, loss, T, alpha_bar, epoch, reporter):\n",
    "    model.train()\n",
    "    total_loss = 0.\n",
    "    for (x0, _) in loader:\n",
    "        optimizer.zero_grad()\n",
    "        x0 = x0.to(device)\n",
    "        # create xt\n",
    "        batch_size = x0.shape[0]\n",
    "        t = torch.randint(0, T, (batch_size,), device=device, dtype=torch.long)\n",
    "        noise = torch.rand_like(x0)\n",
    "        xt = q_sample(x0, t, alpha_bar, noise)\n",
    "        # compute backward noise prediction epsilon_theta\n",
    "        eps_theta = model(xt, t)\n",
    "        # compute loss between true noise and predicted noise\n",
    "        l = loss(noise, eps_theta)\n",
    "        l.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += l.item()\n",
    "    total_loss /= float(len(loader.dataset))\n",
    "    reporter.report(typ='train', loss=total_loss)\n",
    "    print(f\"Train Loss: {total_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def diffusion_sample(model, device, shape, T, alpha_bars, alphas, sigma2s):\n",
    "    xt = torch.randn(shape).to(device)\n",
    "    for i in reversed(range(T)):\n",
    "        t = torch.tensor(i, device=device).repeat(shape[0]) #TODO: dimension correct ?\n",
    "        eps_theta = model(xt, t)\n",
    "        xt = p_sample(xt, eps_theta, device, t, alpha_bars, alphas, sigma2s)\n",
    "    return xt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def diffusion_train_sample(model, device, loader, optimizer, loss, T, shape, alpha_bars, alphas, sigma2s, total_epochs, reporter):\n",
    "    for epoch in range(total_epochs):\n",
    "        diffusion_train(model, device, loader, optimizer, loss, T, alpha_bars, epoch, reporter)\n",
    "        x = diffusion_sample(model, device, shape, T, alpha_bars, alphas, sigma2s)\n",
    "        #to_img(x[0]) #TODO: not working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0002475642381235957\n",
      "Train Loss: 8.592225775122643e-05\n"
     ]
    }
   ],
   "source": [
    "diffusion_train_sample(model, device, loader, optimizer, loss, T, shape, alpha_bar, alpha, sigma2, total_epochs, reporter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = diffusion_sample(model, device, shape, T, alpha_bar, alpha, sigma2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=32x32>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_img(x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
