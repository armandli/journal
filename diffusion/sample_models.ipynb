{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "import math\n",
    "import torch\n",
    "from torch import utils\n",
    "from torch import nn\n",
    "from torch import distributions\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import ToPILImage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/Users/armandli/data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "use_mps = torch.backends.mps.is_built()\n",
    "if use_cuda:\n",
    "    device = torch.device('cuda')\n",
    "elif use_mps:\n",
    "    device = torch.device('mps')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "cpu = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_batch_size = 256\n",
    "loader_args = {'batch_size' : default_batch_size, 'shuffle' : True}\n",
    "score_args = {'batch_size' : default_batch_size, 'shuffle' : False}\n",
    "if use_cuda:\n",
    "    loader_args.update({'pin_memory' : True})\n",
    "    score_args.update({'pin_memory' : True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Reporter(ABC):\n",
    "    @abstractmethod\n",
    "    def report(self, typ, **metric):\n",
    "        pass\n",
    "    @abstractmethod\n",
    "    def reset(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SReporter(Reporter):\n",
    "    def __init__(self):\n",
    "        self.log = []\n",
    "    def report(self, typ, **data):\n",
    "        self.log.append((typ, data))\n",
    "    def reset(self):\n",
    "        self.log.clear()\n",
    "    def loss(self, t):\n",
    "        losses = []\n",
    "        for (typ, data) in self.log:\n",
    "            if typ == t:\n",
    "                losses.append(data['loss'])\n",
    "        return losses\n",
    "    def loss(self, t, idx):\n",
    "        if idx >= 0:\n",
    "            count = 0\n",
    "            for (typ, data) in self.log:\n",
    "                if typ == t:\n",
    "                    if count == idx:\n",
    "                        return data['loss']\n",
    "                    count += 1\n",
    "        else:\n",
    "            count = -1\n",
    "            for (typ, data) in reversed(self.log):\n",
    "                if typ == t:\n",
    "                    if count == idx:\n",
    "                        return data['loss']\n",
    "                    count -= 1\n",
    "        return float(\"inf\")\n",
    "    def eval_loss(self):\n",
    "        return self.loss('eval')\n",
    "    def train_loss(self):\n",
    "        return self.loss('train')\n",
    "    def eval_loss(self, idx):\n",
    "        return self.loss('eval', idx)\n",
    "    def train_loss(self, idx):\n",
    "        return self.loss('train', idx)\n",
    "    def get_record(self, t, idx):\n",
    "        if idx >= 0:\n",
    "            count = 0\n",
    "            for (typ, data) in self.log:\n",
    "                if typ == t:\n",
    "                    if count == idx:\n",
    "                        return data\n",
    "                    count += 1\n",
    "        else:\n",
    "            count = -1\n",
    "            for (typ, data) in reversed(self.log):\n",
    "                if typ == t:\n",
    "                    if count == idx:\n",
    "                        return data\n",
    "                    count -= 1\n",
    "        return dict()\n",
    "    def eval_record(self, idx):\n",
    "        return self.get_record('eval', idx)\n",
    "    def train_record(self, idx):\n",
    "        return self.get_record('train', idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GaussianDistributionV1:\n",
    "    def __init__(self, parameters):\n",
    "        self.mean, log_var = torch.chunk(parameters, 2, dim=1)\n",
    "        self.log_var = torch.clamp(log_var, -30., 20.)\n",
    "        self.std = torch.exp(0.5 * self.log_var)\n",
    "    def sample(self):\n",
    "        return self.mean + self.std * torch.randn_like(self.std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CrossAttentionV1(nn.Module):\n",
    "    def __init__(self, d_model, d_cond, n_heads, d_head, is_inplace=True):\n",
    "        super(CrossAttentionV1, self).__init__()\n",
    "        d_attn = d_head * n_heads\n",
    "        self.is_inplace = is_inplace\n",
    "        self.n_heads = n_heads\n",
    "        self.scale = d_head ** -0.5\n",
    "        self.to_q = nn.Linear(d_model, d_attn, bias=False)\n",
    "        self.to_k = nn.Linear(d_cond, d_attn, bias=False)\n",
    "        self.to_v = nn.Linear(d_cond, d_attn, bias=False)\n",
    "        self.to_out = nn.Sequential(\n",
    "            nn.Linear(d_attn, d_model),\n",
    "        )\n",
    "\n",
    "    \n",
    "    def forward(self, x, cond=None):\n",
    "        has_cond = cond is not None\n",
    "        if not has_cond:\n",
    "            cond = x\n",
    "        q = self.to_q(x)\n",
    "        k = self.to_k(cond)\n",
    "        v = self.to_v(cond)\n",
    "        return self.attention(q, k, v)\n",
    "\n",
    "    def attention(self, q, k, v):\n",
    "        q = q.view(*q.shape[:2], self.n_heads, -1)\n",
    "        k = k.view(*k.shape[:2], self.n_heads, -1)\n",
    "        v = v.view(*v.shape[:2], self.n_heads, -1)\n",
    "        attn = torch.einsum('bihd,bjhd->bhij', q, k) * self.scale\n",
    "        if self.is_inplace:\n",
    "            half = attn.shape[0] // 2\n",
    "            attn[half:] = attn[half:].softmax(dim=-1)\n",
    "            attn[:half] = attn[:half].softmax(dim=-1)\n",
    "        else:\n",
    "            attn = attn.softmax(dim=-1)\n",
    "        out = torch.einsum('bhij,bjhd->bihd', attn, v)\n",
    "        out = out.reshape(*out.shape[:2], -1)\n",
    "        return self.to_out(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GeGLUV1(nn.Module):\n",
    "    def __init__(self, d_in, d_out):\n",
    "        super(GeGLUV1, self).__init__()\n",
    "        self.proj = nn.Linear(d_in, d_out * 2)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x, gate = self.proj(x).chunk(2, dim=-1)\n",
    "        return x * F.gelu(gate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForwardV1(nn.Module):\n",
    "    def __init__(self, d_model, d_mult=4):\n",
    "        super(FeedForwardV1, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            GeGLUV1(d_model, d_model * d_mult),\n",
    "            nn.Dropout(0.), #TODO: not needed ?\n",
    "            nn.Linear(d_model * d_mult, d_model),\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicTransformerBlockV1(nn.Module):\n",
    "    def __init__(self, d_model, n_heads, d_head, d_cond):\n",
    "        super(BasicTransformerBlockV1, self).__init__()\n",
    "        self.attn1 = CrossAttentionV1(d_model, d_model, n_heads, d_head)\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.attn2 = CrossAttentionV1(d_model, d_cond, n_heads, d_head)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        self.ff = FeedForwardV1(d_model)\n",
    "        self.norm3 = nn.LayerNorm(d_model)\n",
    "    \n",
    "    def forward(self, x, cond):\n",
    "        x = self.attn1(self.norm1(x)) + x\n",
    "        x = self.attn2(self.norm2(x), cond=cond) + x\n",
    "        x = self.ff(self.norm3(x)) + x\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpatialTransformerV1(nn.Module):\n",
    "    def __init__(self, channels, n_heads, n_layers, d_cond):\n",
    "        super(SpatialTransformerV1, self).__init__()\n",
    "        self.norm = nn.GroupNorm(num_groups=32, num_channels=channels, eps=1e-6, affine=True)\n",
    "        self.proj_in = nn.Conv2d(channels, channels, kernel_size=1, stride=1, padding=0)\n",
    "        self.transformer_blocks = nn.ModuleList(\n",
    "            [BasicTransformerBlockV1(channels, n_heads, channels // n_heads, d_cond=d_cond) for _ in range(n_layers)]\n",
    "        )\n",
    "        self.proj_out = nn.Conv2d(channels, channels, kernel_size=1, stride=1, padding=0)\n",
    "    \n",
    "    def forward(self, x, cond):\n",
    "        b, c, h, w = x.shape\n",
    "        x_in = x\n",
    "        x = self.norm(x)\n",
    "        x = self.proj_in(x)\n",
    "        x = x.permute(0, 2, 3, 1).view(b, h*w, c)\n",
    "        for block in self.transformer_blocks:\n",
    "            x = block(x, cond)\n",
    "        x = x.view(b, h, w, c).permute(0, 3, 1, 2)\n",
    "        x = self.proj_out(x)\n",
    "        return x + x_in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeEmbeddingV1(nn.Module):\n",
    "    def __init__(self, n_channels):\n",
    "        super(TimeEmbeddingV1, self).__init__()\n",
    "        self.n_channels = n_channels\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(self.n_channels // 4, self.n_channels),\n",
    "            nn.SiLU(inplace=True),\n",
    "            nn.Linear(self.n_channels, self.n_channels),\n",
    "        )\n",
    "\n",
    "    def forward(self, t):\n",
    "        half_dim = self.n_channels // 8\n",
    "        emb = math.log(10_000) * (half_dim - 1)\n",
    "        emb = torch.exp(torch.arange(half_dim, device=t.device) * -emb)\n",
    "        emb = t[:, None] * emb[None, :]\n",
    "        emb = torch.cat((emb.sin(), emb.cos()), dim=1)\n",
    "        emb = self.layers(emb)\n",
    "        return emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeEmbeddingV2(nn.Sequential):\n",
    "    def forward(self, x, t_emb, cond=None):\n",
    "        for layer in self:\n",
    "            if isinstance(layer, ResidualBlockV2): #TODO: what's ResidualBlockV2?\n",
    "                x = layer(x, t_emb)\n",
    "            elif isinstance(layer, SpatialTransformerV1):\n",
    "                x = layer(x, cond)\n",
    "            else:\n",
    "                x = layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: why ?\n",
    "class GroupNorm32(nn.GroupNorm):\n",
    "    def forward(self, x):\n",
    "        return super().forward(x.float()).type(x.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlockV1(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, time_channels, n_groups, dropout):\n",
    "        super(ResidualBlockV1, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.GroupNorm(n_groups, in_channels),\n",
    "            nn.SiLU(inplace=True),\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=(3, 3), padding=(1, 1)),\n",
    "        )\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.GroupNorm(n_groups, out_channels,),\n",
    "            nn.SiLU(inplace=True),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=(3, 3), padding=(1, 1)),\n",
    "        )\n",
    "        self.t_layer = nn.Sequential(\n",
    "            nn.SiLU(inplace=True),\n",
    "            nn.Linear(time_channels, out_channels),\n",
    "        )\n",
    "        if in_channels != out_channels:\n",
    "            self.skip = nn.Conv2d(in_channels, out_channels, kernel_size=(1, 1))\n",
    "        else:\n",
    "            self.skip = nn.Identity()\n",
    "    \n",
    "    def forward(self, x, t):\n",
    "        h = self.layer1(x)\n",
    "        h += self.t_layer(t)[:, :, None, None]\n",
    "        h = self.layer2(h)\n",
    "        return h + self.skip(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only differ by not having the t \n",
    "class ResidualBlockV3(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, n_groups, dropout):\n",
    "        super(ResidualBlockV3, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.GroupNorm(n_groups, in_channels),\n",
    "            nn.SiLU(inplace=True),\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=(3, 3), padding=(1, 1)),\n",
    "        )\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.GroupNorm(n_groups, out_channels,),\n",
    "            nn.SiLU(inplace=True),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=(3, 3), padding=(1, 1)),\n",
    "        )\n",
    "        if in_channels != out_channels:\n",
    "            self.skip = nn.Conv2d(in_channels, out_channels, kernel_size=(1, 1))\n",
    "        else:\n",
    "            self.skip = nn.Identity()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        h = self.layer1(x)\n",
    "        h = self.layer2(h)\n",
    "        return h + self.skip(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionBlockV1(nn.Module):\n",
    "    def __init__(self, n_channels, n_heads, d_k=None, n_groups=32):\n",
    "        super(AttentionBlockV1, self).__init__()\n",
    "        if d_k is None:\n",
    "            d_k = n_channels\n",
    "        self.projection = nn.Linear(n_channels, n_heads * d_k * 3)\n",
    "        self.output = nn.Linear(n_heads * d_k, n_channels)\n",
    "        self.scale = d_k ** -0.5\n",
    "        self.n_heads = n_heads\n",
    "        self.d_k = d_k\n",
    "    \n",
    "    #NOTE: t is not used\n",
    "    def forward(self, x, t=None):\n",
    "        batch_size, n_channels, height, width = x.shape\n",
    "        x = x.view(batch_size, n_channels, -1).permute(0, 2, 1)\n",
    "        qkv = self.projection(x).view(batch_size, -1, self.n_heads, 3 * self.d_k)\n",
    "        q, k, v = torch.chunk(qkv, 3, dim=-1)\n",
    "        attn = torch.einsum('bihd,bjhd->bijh', q, k) * self.scale\n",
    "        attn = attn.softmax(dim=2)\n",
    "        res = torch.einsum('bijh,bjhd->bihd', attn, v)\n",
    "        res = res.view(batch_size, -1, self.n_heads * self.d_k)\n",
    "        res = self.output(res)\n",
    "        res += x\n",
    "        res = res.permute(0, 2, 1).view(batch_size, n_channels, height, width)\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionBlockV2(nn.Module):\n",
    "    def __init__(self, channels):\n",
    "        super(AttentionBlockV2, self).__init__()\n",
    "        self.norm = nn.GroupNorm(32, channels)\n",
    "        self.q = nn.Conv2d(channels, channels, 1)\n",
    "        self.k = nn.Conv2d(channels, channels, 1)\n",
    "        self.v = nn.Conv2d(channels, channels, 1)\n",
    "        self.proj_out = nn.Conv2d(channels, channels, 1)\n",
    "        self.scale = channels ** -0.5\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.norm(x)\n",
    "        q = self.q(x)\n",
    "        k = self.k(x)\n",
    "        v = self.v(x)\n",
    "        b, c, h, w = q.shape\n",
    "        q = q.view(b, c, h * w)\n",
    "        k = k.view(b, c, h * w)\n",
    "        v = v.view(b, c, h * w)\n",
    "        attn = torch.einsum('bci,bcj->bij', q, k) * self.scale\n",
    "        attn = F.softmax(attn, dim=2)\n",
    "        out = torch.einsum('bij,bcj->bci', attn, v)\n",
    "        out = out.view(b, c, h, w)\n",
    "        out = self.proj_out(out)\n",
    "        return x + out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DownBlockV1(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, time_channels, has_attn):\n",
    "        super(DownBlockV1, self).__init__()\n",
    "        self.res = ResidualBlockV1(in_channels, out_channels, time_channels)\n",
    "        if has_attn:\n",
    "            self.attn = AttentionBlockV1(out_channels)\n",
    "        else:\n",
    "            self.attn = nn.Identity()\n",
    "    \n",
    "    def forward(self, x, t):\n",
    "        x = self.res(x, t)\n",
    "        x = self.attn(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DownSampleV1(nn.Module):\n",
    "    def __init__(self, channels):\n",
    "        super(DownSampleV1, self).__init__()\n",
    "        self.conv = nn.Conv2d(channels, channels, 3, stride=2, padding=0)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.pad(x, (0, 1, 0, 1), mode='constant', value=0)\n",
    "        return self.conv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UpBlockV1(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, time_channels, has_attn):\n",
    "        super(UpBlockV1, self).__init__()\n",
    "        self.res = ResidualBlockV1(in_channels + out_channels, out_channels, time_channels)\n",
    "        if has_attn:\n",
    "            self.attn = AttentionBlockV1(out_channels)\n",
    "        else:\n",
    "            self.attn = nn.Identity()\n",
    "    \n",
    "    def forward(self, x, t):\n",
    "        x = self.res(x, t)\n",
    "        x = self.attn(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MiddleBlockV1(nn.Module):\n",
    "    def __init__(self, n_channels, time_channels):\n",
    "        super(MiddleBlockV1, self).__init__()\n",
    "        self.res1 = ResidualBlockV1(n_channels, n_channels, time_channels)\n",
    "        self.attn = AttentionBlockV1(n_channels)\n",
    "        self.res2 = ResidualBlockV1(n_channels, n_channels, time_channels)\n",
    "    \n",
    "    def forward(self, x, t):\n",
    "        x = self.res1(x, t)\n",
    "        x = self.attn(x)\n",
    "        x = self.res2(x, t)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UpSampleV1(nn.Module):\n",
    "    def __init__(self, n_channels):\n",
    "        super(UpSampleV1, self).__init__()\n",
    "        self.conv = nn.ConvTranspose2d(n_channels, n_channels, (4, 4), (2, 2), (1, 1))\n",
    "    \n",
    "    def forward(self, x, t):\n",
    "        return self.conv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UpSampleV2(nn.Module):\n",
    "    def __init__(self, channels):\n",
    "        super(UpSampleV2, self).__init__()\n",
    "        self.conv = nn.Conv2d(channels, channels, 3, padding=1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.interpolate(x, scale_factor=2, mode='nearest')\n",
    "        return self.conv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DownSampleV1(nn.Module):\n",
    "    def __init__(self, n_channels):\n",
    "        super(DownSampleV1, self).__init__()\n",
    "        self.conv = nn.Conv2d(n_channels, n_channels, (3, 3), (2, 2), (1, 1))\n",
    "    \n",
    "    def forward(self, x, t):\n",
    "        return self.conv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlockV2(nn.Module):\n",
    "    def __init__(self, channels, d_t_emb, out_channels=None):\n",
    "        super(ResidualBlockV2, self).__init__()\n",
    "        if out_channels is None:\n",
    "            out_channels = channels\n",
    "        self.in_layers = nn.Sequential(\n",
    "            GroupNorm32(32, channels),\n",
    "            nn.SiLU(inplace=True),\n",
    "            nn.Conv2d(channels, out_channels, 3, padding=1),\n",
    "        )\n",
    "        self.emb_layers = nn.Sequential(\n",
    "            nn.SiLU(inplace=True),\n",
    "            nn.Linear(d_t_emb, out_channels),\n",
    "        )\n",
    "        self.out_layers = nn.Sequential(\n",
    "            GroupNorm32(32, out_channels),\n",
    "            nn.SiLU(inplace=True),\n",
    "            nn.Groupout(0.),\n",
    "            nn.Conv2d(out_channels, out_channels, 3, padding=1),\n",
    "        )\n",
    "        if out_channels == channels:\n",
    "            self.skip = nn.Identity()\n",
    "        else:\n",
    "            self.skip = nn.Conv2d(channels, out_channels, 1)\n",
    "    \n",
    "    def forward(self, x, t_emb):\n",
    "        h = self.in_layers(x)\n",
    "        t_emb = self.emb_layers(t_emb).type(h.dtype)\n",
    "        h = h + t_emb[:, :, None, None]\n",
    "        h = self.out_layers(h)\n",
    "        return self.skip(x) + h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderV1(nn.Module):\n",
    "    def __init__(self, channels, channel_multipliers, n_resnet_blocks, in_channels, z_channels):\n",
    "        super(EncoderV1, self).__init__()\n",
    "        n_resolutions = len(channel_multipliers)\n",
    "        channels_list = [m * channels for m in [1] + channel_multipliers]\n",
    "        self.conv_in = nn.Conv2d(in_channels, channels, 3, stride=1, padding=1)\n",
    "        self.down = nn.ModuleList()\n",
    "        for i in range(n_resolutions):\n",
    "            resnet_blocks = nn.ModuleList()\n",
    "            for _ in range(n_resnet_blocks):\n",
    "                resnet_blocks.append(ResidualBlockV3(channels, channels_list[i+1], 32, 0.0))\n",
    "                channels = channels_list[i+1]\n",
    "            down = nn.Module()\n",
    "            down.block = resnet_blocks\n",
    "            if i != n_resolutions - 1:\n",
    "                down.downsample = DownSampleV1(channels)\n",
    "            else:\n",
    "                down.downsample = nn.Identity()\n",
    "            self.down.append(down)\n",
    "        self.mid = nn.Sequential(\n",
    "            ResidualBlockV3(channels, channels, 32, 0.0),\n",
    "            AttentionBlockV2(channels),\n",
    "            ResidualBlockV3(channels, channels, 32, 0.0),\n",
    "            nn.GroupNorm(32, channels),\n",
    "            nn.SiLU(inplace=True),\n",
    "            nn.Conv2d(channels, 2 * z_channels, 3, stride=1, padding=1),\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv_in(x)\n",
    "        for down in self.down:\n",
    "            for block in down.block:\n",
    "                x = block(x)\n",
    "            x = down.downsample(x)\n",
    "        x = self.mid(x)\n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderV1(nn.Module):\n",
    "    def __init__(self, *, channels, channel_multipliers, n_resnet_blocks, out_channels, z_channels):\n",
    "        super(DecoderV1, self).__init__()\n",
    "        num_resolutions = len(channel_multipliers)\n",
    "        channels_list = [m * channels for m in channel_multipliers]\n",
    "        self.mid = nn.Sequential(\n",
    "            nn.Conv2d(z_channels, channels, 3, stride=1, padding=1),\n",
    "            ResidualBlockV3(channels, channels, 32, 0.0),\n",
    "            AttentionBlockV2(channels),\n",
    "            ResidualBlockV3(channels, channels, 32, 0.0),\n",
    "        )\n",
    "        self.up = nn.ModuleList()\n",
    "        for i in reversed(range(num_resolutions)):\n",
    "            resnet_blocks = nn.ModuleList()\n",
    "            for _ in range(n_resnet_blocks + 1):\n",
    "                resnet_blocks.append(ResidualBlockV3(channels, channels_list[i], 32, 0.0))\n",
    "                channels = channels_list[i]\n",
    "            up = nn.Module()\n",
    "            up.block = resnet_blocks\n",
    "            if i != 0:\n",
    "                up.upsample = UpSampleV2(channels)\n",
    "            else:\n",
    "                up.upsample = nn.Identity()\n",
    "            self.up.insert(0, up)\n",
    "        self.out = nn.Sequentail(\n",
    "            nn.GroupNorm(32, channels),\n",
    "            nn.SiLU(inplace=True),\n",
    "            nn.Conv2d(channels, out_channels, 3, stride=1, padding=1),\n",
    "        )\n",
    "    \n",
    "    def forward(self, z):\n",
    "        h = self.mid(z)\n",
    "        for up in reversed(self.up):\n",
    "            for block in up.block:\n",
    "                h = block(h)\n",
    "            h = up.upsample(h)\n",
    "        x = self.out(h)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoEncoderV1(nn.Module):\n",
    "    def __init__(self, encoder, decoder, emb_channels, z_channels):\n",
    "        super(AutoEncoderV1, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.quant_conv = nn.Conv2d(2 * z_channels, 2 * emb_channels, 1)\n",
    "        self.post_quant_conv = nn.Conv2d(emb_channels, z_channels, 1)\n",
    "    \n",
    "    def encode(self, x):\n",
    "        z = self.encoder(x)\n",
    "        moments = self.quant_conv(z)\n",
    "        return GaussianDistributionV1(moments)\n",
    "\n",
    "    def decode(self, z):\n",
    "        z = self.post_quant_conv(z)\n",
    "        return self.decoder(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNetV1(nn.Module):\n",
    "    def __init__(self, image_channels=3, n_channels=64, ch_mults=(1,2,2,4), is_attn=(False,False,True,True), n_blocks=2):\n",
    "        super(UNetV1, self).__init__()\n",
    "        n_resolution = len(ch_mults)\n",
    "        self.img_proj = nn.Conv2d(image_channels, n_channels, kernel_size=(3, 3), padding=(1,1))\n",
    "        self.time_emb = TimeEmbeddingV1(n_channels * 4)\n",
    "        out_channels = in_channels = n_channels\n",
    "        down = []\n",
    "        for i in range(n_resolution):\n",
    "            out_channels = in_channels * ch_mults[i]\n",
    "            for _ in range(n_blocks):\n",
    "                down.append(DownBlockV1(in_channels, out_channels, n_channels * 4, is_attn[i]))\n",
    "                in_channels = out_channels\n",
    "            if i < n_resolution - 1:\n",
    "                down.append(DownSampleV1(in_channels))\n",
    "        self.down = nn.ModuleList(down)\n",
    "        self.middle = MiddleBlockV1(out_channels, n_channels * 4, )\n",
    "        in_channels = out_channels\n",
    "        up = []\n",
    "        for i in reversed(range(n_resolution)):\n",
    "            out_channels = in_channels\n",
    "            for _ in range(n_blocks):\n",
    "                up.append(UpBlockV1(in_channels, out_channels, n_channels * 4, is_attn[i]))\n",
    "            out_channels = in_channels // ch_mults[i]\n",
    "            up.append(UpBlockV1(in_channels, out_channels, n_channels * 4, is_attn[i]))\n",
    "            in_channels = out_channels\n",
    "            if i > 0:\n",
    "                up.append(UpSampleV1(in_channels))\n",
    "        self.up = nn.ModuleList(up)\n",
    "\n",
    "        self.final = nn.Sequential(\n",
    "            nn.GroupNorm(8, n_channels),\n",
    "            nn.SilU(inplace=True),\n",
    "            nn.Conv2d(in_channels, image_channels, kernel_size=(3,3), padding=(1,1)),\n",
    "        )\n",
    "    \n",
    "    def forward(self, x, t):\n",
    "        t = self.time_emb(t)\n",
    "        x = self.image_proj(x)\n",
    "        h = [x]\n",
    "        for m in self.down:\n",
    "            x = m(x, t)\n",
    "            h.append(x)\n",
    "        x = self.middle(x, t)\n",
    "        for m in self.up:\n",
    "            if isinstance(m, UpSampleV1):\n",
    "                x = m(x, t)\n",
    "            else:\n",
    "                s = h.pop()\n",
    "                x = torch.cat((x, s), dim=1)\n",
    "                x = m(x, t)\n",
    "        return self.final(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNetV2(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, channels, n_res_blocks, attention_levels, channel_multipliers, n_heads, tf_layers=1, d_cond=768):\n",
    "        super(UNetV2, self).__init__()\n",
    "        self.channels = channels\n",
    "        d_time_emb = channels * 4\n",
    "        self.time_embed = nn.Sequential(\n",
    "            nn.Linear(channels, d_time_emb),\n",
    "            nn.SilU(),\n",
    "            nn.Linear(d_time_emb, d_time_emb),\n",
    "        )\n",
    "        self.input_blocks = nn.ModuleList()\n",
    "        levels = len(channel_multipliers)\n",
    "        channels_list = [channels * m for m in channel_multipliers]\n",
    "        input_block_channels = [channels]\n",
    "        self.input_blocks.append(TimeEmbeddingV2(nn.Conv2d(in_channels, channels, 3, padding=1)))\n",
    "        for i in range(levels):\n",
    "            for _ in range(n_res_blocks):\n",
    "                layers = [ResidualBlockV2(channels, d_time_emb, out_channels=channels_list[i])]\n",
    "                channels = channels_list[i]\n",
    "                if i in attention_levels:\n",
    "                    layers.append(SpatialTransformerV1(channels, n_heads, tf_layers, d_cond))\n",
    "                self.input_blocks.append(TimeEmbeddingV2(*layers))\n",
    "                input_block_channels.append(channels)\n",
    "            if i != levels - 1:\n",
    "                self.input_blocks.append(TimeEmbeddingV2(DownSampleV1(channels)))\n",
    "                input_block_channels.append(channels)\n",
    "        self.middle_block = TimeEmbeddingV2(\n",
    "            ResidualBlockV2(channels, d_time_emb),\n",
    "            SpatialTransformerV1(channels, n_heads, tf_layers, d_cond),\n",
    "            ResidualBlockV2(channels, d_time_emb),\n",
    "        )\n",
    "        self.output_blocks = nn.ModuleList()\n",
    "        for i in reversed(range(levels)):\n",
    "            for j in range(n_res_blocks + 1):\n",
    "                layers = [ResidualBlockV2(channels + input_block_channels.pop(), d_time_emb, out_channels=channels_list[i])]\n",
    "                channels = channels_list[i]\n",
    "                if i in attention_levels:\n",
    "                    layers.append(SpatialTransformerV1(channels, n_heads, tf_layers, d_cond))\n",
    "                if i != 0 and j == n_res_blocks:\n",
    "                    layers.apppend(UpSampleV2(channels))\n",
    "                self.output_blocks.append(TimeEmbeddingV2(*layers))\n",
    "        self.out = nn.Sequential(\n",
    "            GroupNorm32(32, channels),\n",
    "            nn.SiLU(inplace=True),\n",
    "            nn.Conv2d(channels, out_channels, 3, padding=1),\n",
    "        )\n",
    "    \n",
    "    #TODO: this is similar to TimeEmbedding Module\n",
    "    def time_step_embedding(self, time_steps, max_period=10000):\n",
    "        half = self.channels // 2\n",
    "        freqs = torch.exp(-math.log(max_period) * torch.arange(start=0,end=half,dtype=torch.float32)/half).to(device=time_steps.device)\n",
    "        args = time_steps[:, None].float() * freqs[None]\n",
    "        return torch.cat([torch.cos(args), torch.sin(args)], dim=-1)\n",
    "\n",
    "    def forward(self, x, time_steps, cond):\n",
    "        t_emb = self.time_step_embedding(time_steps)\n",
    "        t_emb = self.time_embed(t_emb)\n",
    "        x_input_block = []\n",
    "        for module in self.input_blocks:\n",
    "            x = module(x, t_emb, cond)\n",
    "            x_input_block.append(x)\n",
    "        x = self.middle_block(x, t_emb, cond)\n",
    "        for module in self.output_blocks:\n",
    "            x = torch.cat([x, x_input_block.pop()], dim=1)\n",
    "            x = module(x, t_emb, cond)\n",
    "        return self.out(x)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
