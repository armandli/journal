{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils as utils\n",
    "import torch.utils.data as data\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset contains an anonymized set of features, feature_{0...129}, representing real stock market data. Each row in the dataset represents a trading opportunity, for which you will be predicting an action value: 1 to make the trade and 0 to pass on it. Each trade has an associated weight and resp, which together represents a return on the trade. The date column is an integer which represents the day of the trade, while ts_id represents a time ordering. In addition to anonymized feature values, you are provided with metadata about the features in features.csv.\n",
    "\n",
    "In the training set, train.csv, you are provided a resp value, as well as several other resp_{1,2,3,4} values that represent returns over different time horizons. These variables are not included in the test set. Trades with weight = 0 were intentionally included in the dataset for completeness, although such trades will not contribute towards the scoring evaluation.\n",
    "\n",
    "This is a code competition that relies on a time-series API to ensure models do not peek forward in time. To use the API, follow the instructions on the Evaluation page. When you submit your notebook, it will be rerun on an unseen test:\n",
    "\n",
    "    During the model training phase of the competition, this unseen test set is comprised of approximately 1 million rows of historical data.\n",
    "    During the live forecasting phase, the test set will use periodically updated live market data.\n",
    "\n",
    "Note that during the second (forecasting) phase of the competition, the notebook time limits will scale with the number of trades presented in the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>weight</th>\n",
       "      <th>resp_1</th>\n",
       "      <th>resp_2</th>\n",
       "      <th>resp_3</th>\n",
       "      <th>resp_4</th>\n",
       "      <th>resp</th>\n",
       "      <th>feature_0</th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>...</th>\n",
       "      <th>feature_121</th>\n",
       "      <th>feature_122</th>\n",
       "      <th>feature_123</th>\n",
       "      <th>feature_124</th>\n",
       "      <th>feature_125</th>\n",
       "      <th>feature_126</th>\n",
       "      <th>feature_127</th>\n",
       "      <th>feature_128</th>\n",
       "      <th>feature_129</th>\n",
       "      <th>ts_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009916</td>\n",
       "      <td>0.014079</td>\n",
       "      <td>0.008773</td>\n",
       "      <td>0.001390</td>\n",
       "      <td>0.006270</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.872746</td>\n",
       "      <td>-2.191242</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.168391</td>\n",
       "      <td>8.313583</td>\n",
       "      <td>1.782433</td>\n",
       "      <td>14.018213</td>\n",
       "      <td>2.653056</td>\n",
       "      <td>12.600292</td>\n",
       "      <td>2.301488</td>\n",
       "      <td>11.445807</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>16.673515</td>\n",
       "      <td>-0.002828</td>\n",
       "      <td>-0.003226</td>\n",
       "      <td>-0.007319</td>\n",
       "      <td>-0.011114</td>\n",
       "      <td>-0.009792</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.349537</td>\n",
       "      <td>-1.704709</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.178850</td>\n",
       "      <td>1.777472</td>\n",
       "      <td>-0.915458</td>\n",
       "      <td>2.831612</td>\n",
       "      <td>-1.417010</td>\n",
       "      <td>2.297459</td>\n",
       "      <td>-1.304614</td>\n",
       "      <td>1.898684</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.025134</td>\n",
       "      <td>0.027607</td>\n",
       "      <td>0.033406</td>\n",
       "      <td>0.034380</td>\n",
       "      <td>0.023970</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.812780</td>\n",
       "      <td>-0.256156</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.115747</td>\n",
       "      <td>9.667908</td>\n",
       "      <td>5.542871</td>\n",
       "      <td>11.671595</td>\n",
       "      <td>7.281757</td>\n",
       "      <td>10.060014</td>\n",
       "      <td>6.638248</td>\n",
       "      <td>9.427299</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.004730</td>\n",
       "      <td>-0.003273</td>\n",
       "      <td>-0.000461</td>\n",
       "      <td>-0.000476</td>\n",
       "      <td>-0.003200</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.174378</td>\n",
       "      <td>0.344640</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.838853</td>\n",
       "      <td>0.499251</td>\n",
       "      <td>3.033732</td>\n",
       "      <td>1.513488</td>\n",
       "      <td>4.397532</td>\n",
       "      <td>1.266037</td>\n",
       "      <td>3.856384</td>\n",
       "      <td>1.013469</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.138531</td>\n",
       "      <td>0.001252</td>\n",
       "      <td>0.002165</td>\n",
       "      <td>-0.001215</td>\n",
       "      <td>-0.006219</td>\n",
       "      <td>-0.002604</td>\n",
       "      <td>1</td>\n",
       "      <td>-3.172026</td>\n",
       "      <td>-3.093182</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.344850</td>\n",
       "      <td>4.101145</td>\n",
       "      <td>0.614252</td>\n",
       "      <td>6.623456</td>\n",
       "      <td>0.800129</td>\n",
       "      <td>5.233243</td>\n",
       "      <td>0.362636</td>\n",
       "      <td>3.926633</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2390486</th>\n",
       "      <td>499</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000142</td>\n",
       "      <td>0.000142</td>\n",
       "      <td>0.005829</td>\n",
       "      <td>0.020342</td>\n",
       "      <td>0.015396</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.649365</td>\n",
       "      <td>-1.169996</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.896874</td>\n",
       "      <td>-1.260055</td>\n",
       "      <td>1.947725</td>\n",
       "      <td>-1.994399</td>\n",
       "      <td>-1.685163</td>\n",
       "      <td>-2.866165</td>\n",
       "      <td>-0.216130</td>\n",
       "      <td>-1.892048</td>\n",
       "      <td>0.901585</td>\n",
       "      <td>2390486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2390487</th>\n",
       "      <td>499</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>-0.000935</td>\n",
       "      <td>-0.006326</td>\n",
       "      <td>-0.004718</td>\n",
       "      <td>1</td>\n",
       "      <td>2.432943</td>\n",
       "      <td>5.284504</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.936553</td>\n",
       "      <td>1.064936</td>\n",
       "      <td>3.119762</td>\n",
       "      <td>-0.419796</td>\n",
       "      <td>-0.208975</td>\n",
       "      <td>-0.146749</td>\n",
       "      <td>0.730166</td>\n",
       "      <td>0.648452</td>\n",
       "      <td>2.068737</td>\n",
       "      <td>2390487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2390488</th>\n",
       "      <td>499</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000499</td>\n",
       "      <td>0.000499</td>\n",
       "      <td>0.007605</td>\n",
       "      <td>0.024907</td>\n",
       "      <td>0.016591</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.622475</td>\n",
       "      <td>-0.963682</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.956745</td>\n",
       "      <td>-0.640334</td>\n",
       "      <td>-2.279663</td>\n",
       "      <td>-0.950259</td>\n",
       "      <td>-4.388417</td>\n",
       "      <td>-1.669922</td>\n",
       "      <td>-3.288939</td>\n",
       "      <td>-1.336142</td>\n",
       "      <td>-2.814239</td>\n",
       "      <td>2390488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2390489</th>\n",
       "      <td>499</td>\n",
       "      <td>0.283405</td>\n",
       "      <td>-0.000156</td>\n",
       "      <td>-0.000156</td>\n",
       "      <td>-0.001375</td>\n",
       "      <td>-0.003702</td>\n",
       "      <td>-0.002004</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.463757</td>\n",
       "      <td>-1.107228</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.035894</td>\n",
       "      <td>-1.780962</td>\n",
       "      <td>0.881246</td>\n",
       "      <td>-2.202140</td>\n",
       "      <td>-1.912601</td>\n",
       "      <td>-3.341684</td>\n",
       "      <td>-0.571188</td>\n",
       "      <td>-2.185795</td>\n",
       "      <td>0.627452</td>\n",
       "      <td>2390489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2390490</th>\n",
       "      <td>499</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.001855</td>\n",
       "      <td>-0.001855</td>\n",
       "      <td>-0.001194</td>\n",
       "      <td>-0.000864</td>\n",
       "      <td>-0.001905</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.817184</td>\n",
       "      <td>-1.131577</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.571013</td>\n",
       "      <td>2.483421</td>\n",
       "      <td>8.284037</td>\n",
       "      <td>-0.698486</td>\n",
       "      <td>0.199953</td>\n",
       "      <td>-0.168395</td>\n",
       "      <td>2.051091</td>\n",
       "      <td>1.726072</td>\n",
       "      <td>5.823676</td>\n",
       "      <td>2390490</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2390491 rows × 138 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         date     weight    resp_1    resp_2    resp_3    resp_4      resp  \\\n",
       "0           0   0.000000  0.009916  0.014079  0.008773  0.001390  0.006270   \n",
       "1           0  16.673515 -0.002828 -0.003226 -0.007319 -0.011114 -0.009792   \n",
       "2           0   0.000000  0.025134  0.027607  0.033406  0.034380  0.023970   \n",
       "3           0   0.000000 -0.004730 -0.003273 -0.000461 -0.000476 -0.003200   \n",
       "4           0   0.138531  0.001252  0.002165 -0.001215 -0.006219 -0.002604   \n",
       "...       ...        ...       ...       ...       ...       ...       ...   \n",
       "2390486   499   0.000000  0.000142  0.000142  0.005829  0.020342  0.015396   \n",
       "2390487   499   0.000000  0.000012  0.000012 -0.000935 -0.006326 -0.004718   \n",
       "2390488   499   0.000000  0.000499  0.000499  0.007605  0.024907  0.016591   \n",
       "2390489   499   0.283405 -0.000156 -0.000156 -0.001375 -0.003702 -0.002004   \n",
       "2390490   499   0.000000 -0.001855 -0.001855 -0.001194 -0.000864 -0.001905   \n",
       "\n",
       "         feature_0  feature_1  feature_2  ...  feature_121  feature_122  \\\n",
       "0                1  -1.872746  -2.191242  ...          NaN     1.168391   \n",
       "1               -1  -1.349537  -1.704709  ...          NaN    -1.178850   \n",
       "2               -1   0.812780  -0.256156  ...          NaN     6.115747   \n",
       "3               -1   1.174378   0.344640  ...          NaN     2.838853   \n",
       "4                1  -3.172026  -3.093182  ...          NaN     0.344850   \n",
       "...            ...        ...        ...  ...          ...          ...   \n",
       "2390486          1  -1.649365  -1.169996  ...    -1.896874    -1.260055   \n",
       "2390487          1   2.432943   5.284504  ...    -0.936553     1.064936   \n",
       "2390488          1  -0.622475  -0.963682  ...    -2.956745    -0.640334   \n",
       "2390489         -1  -1.463757  -1.107228  ...    -2.035894    -1.780962   \n",
       "2390490         -1  -1.817184  -1.131577  ...    -0.571013     2.483421   \n",
       "\n",
       "         feature_123  feature_124  feature_125  feature_126  feature_127  \\\n",
       "0           8.313583     1.782433    14.018213     2.653056    12.600292   \n",
       "1           1.777472    -0.915458     2.831612    -1.417010     2.297459   \n",
       "2           9.667908     5.542871    11.671595     7.281757    10.060014   \n",
       "3           0.499251     3.033732     1.513488     4.397532     1.266037   \n",
       "4           4.101145     0.614252     6.623456     0.800129     5.233243   \n",
       "...              ...          ...          ...          ...          ...   \n",
       "2390486     1.947725    -1.994399    -1.685163    -2.866165    -0.216130   \n",
       "2390487     3.119762    -0.419796    -0.208975    -0.146749     0.730166   \n",
       "2390488    -2.279663    -0.950259    -4.388417    -1.669922    -3.288939   \n",
       "2390489     0.881246    -2.202140    -1.912601    -3.341684    -0.571188   \n",
       "2390490     8.284037    -0.698486     0.199953    -0.168395     2.051091   \n",
       "\n",
       "         feature_128  feature_129    ts_id  \n",
       "0           2.301488    11.445807        0  \n",
       "1          -1.304614     1.898684        1  \n",
       "2           6.638248     9.427299        2  \n",
       "3           3.856384     1.013469        3  \n",
       "4           0.362636     3.926633        4  \n",
       "...              ...          ...      ...  \n",
       "2390486    -1.892048     0.901585  2390486  \n",
       "2390487     0.648452     2.068737  2390487  \n",
       "2390488    -1.336142    -2.814239  2390488  \n",
       "2390489    -2.185795     0.627452  2390489  \n",
       "2390490     1.726072     5.823676  2390490  \n",
       "\n",
       "[2390491 rows x 138 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.read_csv('../data/jane_street_train.csv')\n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['date', 'weight', 'resp_1', 'resp_2', 'resp_3', 'resp_4', 'resp',\n",
       "       'feature_0', 'feature_1', 'feature_2',\n",
       "       ...\n",
       "       'feature_121', 'feature_122', 'feature_123', 'feature_124',\n",
       "       'feature_125', 'feature_126', 'feature_127', 'feature_128',\n",
       "       'feature_129', 'ts_id'],\n",
       "      dtype='object', length=138)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2390491"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>weight</th>\n",
       "      <th>feature_0</th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>feature_4</th>\n",
       "      <th>feature_5</th>\n",
       "      <th>feature_6</th>\n",
       "      <th>feature_7</th>\n",
       "      <th>feature_8</th>\n",
       "      <th>...</th>\n",
       "      <th>feature_122</th>\n",
       "      <th>feature_123</th>\n",
       "      <th>feature_124</th>\n",
       "      <th>feature_125</th>\n",
       "      <th>feature_126</th>\n",
       "      <th>feature_127</th>\n",
       "      <th>feature_128</th>\n",
       "      <th>feature_129</th>\n",
       "      <th>date</th>\n",
       "      <th>ts_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.872746</td>\n",
       "      <td>-2.191242</td>\n",
       "      <td>-0.474163</td>\n",
       "      <td>-0.323046</td>\n",
       "      <td>0.014688</td>\n",
       "      <td>-0.002484</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.168391</td>\n",
       "      <td>8.313583</td>\n",
       "      <td>1.782433</td>\n",
       "      <td>14.018213</td>\n",
       "      <td>2.653056</td>\n",
       "      <td>12.600292</td>\n",
       "      <td>2.301488</td>\n",
       "      <td>11.445807</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16.673515</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.349537</td>\n",
       "      <td>-1.704709</td>\n",
       "      <td>0.068058</td>\n",
       "      <td>0.028432</td>\n",
       "      <td>0.193794</td>\n",
       "      <td>0.138212</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.178850</td>\n",
       "      <td>1.777472</td>\n",
       "      <td>-0.915458</td>\n",
       "      <td>2.831612</td>\n",
       "      <td>-1.417010</td>\n",
       "      <td>2.297459</td>\n",
       "      <td>-1.304614</td>\n",
       "      <td>1.898684</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.812780</td>\n",
       "      <td>-0.256156</td>\n",
       "      <td>0.806463</td>\n",
       "      <td>0.400221</td>\n",
       "      <td>-0.614188</td>\n",
       "      <td>-0.354800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>6.115747</td>\n",
       "      <td>9.667908</td>\n",
       "      <td>5.542871</td>\n",
       "      <td>11.671595</td>\n",
       "      <td>7.281757</td>\n",
       "      <td>10.060014</td>\n",
       "      <td>6.638248</td>\n",
       "      <td>9.427299</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.174378</td>\n",
       "      <td>0.344640</td>\n",
       "      <td>0.066872</td>\n",
       "      <td>0.009357</td>\n",
       "      <td>-1.006373</td>\n",
       "      <td>-0.676458</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2.838853</td>\n",
       "      <td>0.499251</td>\n",
       "      <td>3.033732</td>\n",
       "      <td>1.513488</td>\n",
       "      <td>4.397532</td>\n",
       "      <td>1.266037</td>\n",
       "      <td>3.856384</td>\n",
       "      <td>1.013469</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.138531</td>\n",
       "      <td>1</td>\n",
       "      <td>-3.172026</td>\n",
       "      <td>-3.093182</td>\n",
       "      <td>-0.161518</td>\n",
       "      <td>-0.128149</td>\n",
       "      <td>-0.195006</td>\n",
       "      <td>-0.143780</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.344850</td>\n",
       "      <td>4.101145</td>\n",
       "      <td>0.614252</td>\n",
       "      <td>6.623456</td>\n",
       "      <td>0.800129</td>\n",
       "      <td>5.233243</td>\n",
       "      <td>0.362636</td>\n",
       "      <td>3.926633</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15214</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.213240</td>\n",
       "      <td>-1.557117</td>\n",
       "      <td>0.530793</td>\n",
       "      <td>0.382429</td>\n",
       "      <td>0.316811</td>\n",
       "      <td>0.240976</td>\n",
       "      <td>0.741902</td>\n",
       "      <td>0.680989</td>\n",
       "      <td>...</td>\n",
       "      <td>1.655182</td>\n",
       "      <td>2.551488</td>\n",
       "      <td>0.525934</td>\n",
       "      <td>1.242721</td>\n",
       "      <td>1.977483</td>\n",
       "      <td>2.563083</td>\n",
       "      <td>1.857149</td>\n",
       "      <td>2.424928</td>\n",
       "      <td>2</td>\n",
       "      <td>15214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15215</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.413328</td>\n",
       "      <td>-0.642504</td>\n",
       "      <td>0.429951</td>\n",
       "      <td>0.333967</td>\n",
       "      <td>-0.728263</td>\n",
       "      <td>-0.637617</td>\n",
       "      <td>0.204294</td>\n",
       "      <td>0.138052</td>\n",
       "      <td>...</td>\n",
       "      <td>6.393191</td>\n",
       "      <td>22.159397</td>\n",
       "      <td>-0.101824</td>\n",
       "      <td>3.804838</td>\n",
       "      <td>1.780150</td>\n",
       "      <td>7.504901</td>\n",
       "      <td>4.702145</td>\n",
       "      <td>15.376130</td>\n",
       "      <td>2</td>\n",
       "      <td>15215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15216</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.378947</td>\n",
       "      <td>-1.702976</td>\n",
       "      <td>0.548763</td>\n",
       "      <td>0.396754</td>\n",
       "      <td>0.328203</td>\n",
       "      <td>0.249898</td>\n",
       "      <td>0.784458</td>\n",
       "      <td>0.730435</td>\n",
       "      <td>...</td>\n",
       "      <td>1.740141</td>\n",
       "      <td>2.685696</td>\n",
       "      <td>0.527251</td>\n",
       "      <td>1.245219</td>\n",
       "      <td>1.981606</td>\n",
       "      <td>2.567519</td>\n",
       "      <td>1.876328</td>\n",
       "      <td>2.450874</td>\n",
       "      <td>2</td>\n",
       "      <td>15216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15217</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.324708</td>\n",
       "      <td>-1.089962</td>\n",
       "      <td>-0.873900</td>\n",
       "      <td>-0.544143</td>\n",
       "      <td>-1.265208</td>\n",
       "      <td>-0.844335</td>\n",
       "      <td>2.302628</td>\n",
       "      <td>1.978776</td>\n",
       "      <td>...</td>\n",
       "      <td>5.243907</td>\n",
       "      <td>11.789678</td>\n",
       "      <td>0.310616</td>\n",
       "      <td>2.660067</td>\n",
       "      <td>3.052869</td>\n",
       "      <td>6.399390</td>\n",
       "      <td>5.396259</td>\n",
       "      <td>10.972647</td>\n",
       "      <td>2</td>\n",
       "      <td>15217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15218</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.652183</td>\n",
       "      <td>-1.857245</td>\n",
       "      <td>0.451629</td>\n",
       "      <td>0.352413</td>\n",
       "      <td>-0.716532</td>\n",
       "      <td>-0.626735</td>\n",
       "      <td>0.268371</td>\n",
       "      <td>0.208574</td>\n",
       "      <td>...</td>\n",
       "      <td>6.423787</td>\n",
       "      <td>22.254007</td>\n",
       "      <td>-0.098530</td>\n",
       "      <td>3.816995</td>\n",
       "      <td>1.793470</td>\n",
       "      <td>7.534632</td>\n",
       "      <td>4.730957</td>\n",
       "      <td>15.457871</td>\n",
       "      <td>2</td>\n",
       "      <td>15218</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15219 rows × 133 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          weight  feature_0  feature_1  feature_2  feature_3  feature_4  \\\n",
       "0       0.000000          1  -1.872746  -2.191242  -0.474163  -0.323046   \n",
       "1      16.673515         -1  -1.349537  -1.704709   0.068058   0.028432   \n",
       "2       0.000000         -1   0.812780  -0.256156   0.806463   0.400221   \n",
       "3       0.000000         -1   1.174378   0.344640   0.066872   0.009357   \n",
       "4       0.138531          1  -3.172026  -3.093182  -0.161518  -0.128149   \n",
       "...          ...        ...        ...        ...        ...        ...   \n",
       "15214   0.000000          1  -1.213240  -1.557117   0.530793   0.382429   \n",
       "15215   0.000000          1  -0.413328  -0.642504   0.429951   0.333967   \n",
       "15216   0.000000          1  -1.378947  -1.702976   0.548763   0.396754   \n",
       "15217   0.000000          1  -0.324708  -1.089962  -0.873900  -0.544143   \n",
       "15218   0.000000          1  -1.652183  -1.857245   0.451629   0.352413   \n",
       "\n",
       "       feature_5  feature_6  feature_7  feature_8  ...  feature_122  \\\n",
       "0       0.014688  -0.002484        NaN        NaN  ...     1.168391   \n",
       "1       0.193794   0.138212        NaN        NaN  ...    -1.178850   \n",
       "2      -0.614188  -0.354800        NaN        NaN  ...     6.115747   \n",
       "3      -1.006373  -0.676458        NaN        NaN  ...     2.838853   \n",
       "4      -0.195006  -0.143780        NaN        NaN  ...     0.344850   \n",
       "...          ...        ...        ...        ...  ...          ...   \n",
       "15214   0.316811   0.240976   0.741902   0.680989  ...     1.655182   \n",
       "15215  -0.728263  -0.637617   0.204294   0.138052  ...     6.393191   \n",
       "15216   0.328203   0.249898   0.784458   0.730435  ...     1.740141   \n",
       "15217  -1.265208  -0.844335   2.302628   1.978776  ...     5.243907   \n",
       "15218  -0.716532  -0.626735   0.268371   0.208574  ...     6.423787   \n",
       "\n",
       "       feature_123  feature_124  feature_125  feature_126  feature_127  \\\n",
       "0         8.313583     1.782433    14.018213     2.653056    12.600292   \n",
       "1         1.777472    -0.915458     2.831612    -1.417010     2.297459   \n",
       "2         9.667908     5.542871    11.671595     7.281757    10.060014   \n",
       "3         0.499251     3.033732     1.513488     4.397532     1.266037   \n",
       "4         4.101145     0.614252     6.623456     0.800129     5.233243   \n",
       "...            ...          ...          ...          ...          ...   \n",
       "15214     2.551488     0.525934     1.242721     1.977483     2.563083   \n",
       "15215    22.159397    -0.101824     3.804838     1.780150     7.504901   \n",
       "15216     2.685696     0.527251     1.245219     1.981606     2.567519   \n",
       "15217    11.789678     0.310616     2.660067     3.052869     6.399390   \n",
       "15218    22.254007    -0.098530     3.816995     1.793470     7.534632   \n",
       "\n",
       "       feature_128  feature_129  date  ts_id  \n",
       "0         2.301488    11.445807     0      0  \n",
       "1        -1.304614     1.898684     0      1  \n",
       "2         6.638248     9.427299     0      2  \n",
       "3         3.856384     1.013469     0      3  \n",
       "4         0.362636     3.926633     0      4  \n",
       "...            ...          ...   ...    ...  \n",
       "15214     1.857149     2.424928     2  15214  \n",
       "15215     4.702145    15.376130     2  15215  \n",
       "15216     1.876328     2.450874     2  15216  \n",
       "15217     5.396259    10.972647     2  15217  \n",
       "15218     4.730957    15.457871     2  15218  \n",
       "\n",
       "[15219 rows x 133 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = pd.read_csv('../data/jane_street_example_test.csv')\n",
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['weight', 'feature_0', 'feature_1', 'feature_2', 'feature_3',\n",
       "       'feature_4', 'feature_5', 'feature_6', 'feature_7', 'feature_8',\n",
       "       ...\n",
       "       'feature_122', 'feature_123', 'feature_124', 'feature_125',\n",
       "       'feature_126', 'feature_127', 'feature_128', 'feature_129', 'date',\n",
       "       'ts_id'],\n",
       "      dtype='object', length=133)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5587"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data.query(\"date == 0\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_columns = [column for column in train_data.columns.to_list() if 'feature' in column]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device('cuda' if use_cuda else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_feature_columns = 130"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = '../data/jane_street_train.csv'\n",
    "test_file = '../data/jane_street_example_test.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "\n",
    "class StatsCollector(ABC):\n",
    "    @abstractmethod\n",
    "    def train_gather(self, epoch, batch_idx, batch_size, dataset_size, loss):\n",
    "        pass\n",
    "    @abstractmethod\n",
    "    def eval_gather(self, train_epoch, loss, accuracy):\n",
    "        pass\n",
    "    @abstractmethod\n",
    "    def eval_pred_gather(self, train_epoch, predictions, targets):\n",
    "        pass\n",
    "    @abstractmethod\n",
    "    def train_reset(self):\n",
    "        pass\n",
    "    @abstractmethod\n",
    "    def eval_reset(self):\n",
    "        pass\n",
    "\n",
    "class EpochLossCollector(StatsCollector):\n",
    "    def __init__(self, batch_size, frequency, report_frequency = 0, eval_report_frequency = 0):\n",
    "        self.batch_size = batch_size\n",
    "        self.frequency = frequency\n",
    "        self.report_frequency = report_frequency\n",
    "        self.eval_report_frequency = eval_report_frequency\n",
    "        self.losses = []\n",
    "        self.eval_losses = []\n",
    "        self.eval_predictions_targets = []\n",
    "    def train_gather(self, epoch, batch_idx, dataset_size, loss):\n",
    "        if epoch % self.frequency == 0 and (batch_idx + 1) * self.batch_size >= dataset_size:\n",
    "            self.losses.append((epoch, loss))\n",
    "        if self.report_frequency > 0 and epoch % self.report_frequency == 0 and (batch_idx + 1) * self.batch_size >= dataset_size:\n",
    "            print(\"Epoch {}, {}/{}: {}\".format(epoch, batch_idx * self.batch_size, dataset_size, loss))\n",
    "    def eval_gather(self, train_epoch, loss, accuracy):\n",
    "        self.eval_losses.append((train_epoch, loss, accuracy))\n",
    "        if self.eval_report_frequency > 0 and train_epoch % self.eval_report_frequency == 0:\n",
    "            print(\"Epoch {}: loss {} accuracy {}\".format(train_epoch, loss, accuracy))\n",
    "    def eval_pred_gather(self, train_epoch, predictions, targets):\n",
    "        self.eval_predictions_targets.append((train_epoch, predictions, targets))\n",
    "    def train_reset(self):\n",
    "        self.losses = []\n",
    "    def eval_reset(self):\n",
    "        self.eval_losses = []\n",
    "        self.eval_predictions_targets = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class JSClassificationDataset(data.Dataset):\n",
    "    def __init__(self, filename, transform=None, target_transform=None):\n",
    "        data = pd.read_csv(filename)\n",
    "        data = data.fillna(0.)\n",
    "        feature_columns = [column for column in data.columns if 'feature' in column]\n",
    "        target_column = 'resp'\n",
    "        data['y'] = data[target_column] > 0.0\n",
    "        self.x = torch.tensor(data[feature_columns].values, dtype=torch.float32)\n",
    "        self.y = torch.tensor(data['y'].values, dtype=torch.float32)\n",
    "        self.y = self.y.reshape([self.y.shape[0], 1])\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "    def __getitem__(self, index):\n",
    "        x = self.x[index]\n",
    "        y = self.y[index]\n",
    "        if self.transform is not None:\n",
    "            x = self.transform(x)\n",
    "        if self.target_transform is not None:\n",
    "            y = self.target_transform(y)\n",
    "        return x, y\n",
    "    def __len__(self):\n",
    "        return len(self.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, device, loader, optimizer, loss, epoch, collector):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        l = loss(output, target)\n",
    "        l.backward()\n",
    "        optimizer.step()\n",
    "        collector.train_gather(epoch, batch_idx, len(loader.dataset), l.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classification_validate(model, device, loader, loss, train_epoch, collector):\n",
    "    model.eval()\n",
    "    total_loss = 0.\n",
    "    total_corrects = 0.\n",
    "    with torch.no_grad():\n",
    "        for data, target in loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            total_loss += loss(output, target).item()\n",
    "            pred = (output > 0.5).type(torch.float32)\n",
    "            collector.eval_pred_gather(train_epoch, pred, target)\n",
    "            corrects = pred.eq(target.view_as(pred)).sum().item()\n",
    "            total_corrects += corrects\n",
    "    total_loss /= len(loader.dataset)\n",
    "    accuracy = total_corrects / len(loader.dataset)\n",
    "    collector.eval_gather(train_epoch, total_loss, accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_batch_size = 128\n",
    "loader_args = {'batch_size' : default_batch_size, 'shuffle' : True}\n",
    "if use_cuda:\n",
    "    loader_args.update({'pin_memory' : True, 'num_workers' : 0})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPClassifier1(nn.Module):\n",
    "    def __init__(self, isize):\n",
    "        super(MLPClassifier1, self).__init__()\n",
    "        self.fc1 = nn.Linear(isize, 1000)\n",
    "        self.relu1 = nn.ReLU(inplace=True)\n",
    "        self.fc2 = nn.Linear(1000, 1)\n",
    "        self.sigmoid2 = nn.Sigmoid()\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.sigmoid2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_modelfile = '../models/js_mlp_model1.pt'\n",
    "mlp_model = MLPClassifier1(num_feature_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_model = mlp_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = JSClassificationDataset(train_file)\n",
    "train_loader = data.DataLoader(trainset, **loader_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "total_epochs = 10\n",
    "optimizer = optim.Adam(mlp_model.parameters(), lr=learning_rate)\n",
    "loss = nn.BCELoss()\n",
    "collector = EpochLossCollector(default_batch_size, 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, 2390400/2390491: 0.6939966678619385\n",
      "Epoch 1, 2390400/2390491: 0.7136209011077881\n",
      "Epoch 2, 2390400/2390491: 0.7101637721061707\n",
      "Epoch 3, 2390400/2390491: 0.6985130310058594\n",
      "Epoch 4, 2390400/2390491: 0.6766823530197144\n",
      "Epoch 5, 2390400/2390491: 0.674554169178009\n",
      "Epoch 6, 2390400/2390491: 0.6836362481117249\n",
      "Epoch 7, 2390400/2390491: 0.6665523648262024\n",
      "Epoch 8, 2390400/2390491: 0.6906943321228027\n",
      "Epoch 9, 2390400/2390491: 0.6835135221481323\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(total_epochs):\n",
    "    train(mlp_model, device, train_loader, optimizer, loss, epoch, collector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_validate(mlp_model, device, train_loader, loss, total_epochs, collector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(10, 0.005382537147133978, 0.5323722197657301)]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collector.eval_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(mlp_model, mlp_modelfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resnet Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "attemping to overfit training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResnetLayerV1(nn.Module):\n",
    "    def __init__(self, isize, a1, a2):\n",
    "        super(ResnetLayerV1, self).__init__()\n",
    "        self.fc1 = nn.Linear(isize, isize)\n",
    "        self.fc2 = nn.Linear(isize, isize)\n",
    "        self.a1 = a1\n",
    "        self.a2 = a2\n",
    "    def forward(self, x):\n",
    "        s = x\n",
    "        x = self.fc1(x)\n",
    "        x = self.a1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = x + s\n",
    "        x = self.a2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResnetLayerV2(nn.Module):\n",
    "    def __init__(self, isize, a1, a2):\n",
    "        super(ResnetLayerV2, self).__init__()\n",
    "        self.fc1 = nn.Linear(isize, isize)\n",
    "        self.fc2 = nn.Linear(isize, isize)\n",
    "        self.a1 = a1\n",
    "        self.a2 = a2\n",
    "    def forward(self, x):\n",
    "        s = x\n",
    "        x = self.a1(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.a2(x)\n",
    "        x = self.fc2(x)\n",
    "        x = x + s\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResnetClassifier1(nn.Module):\n",
    "    def __init__(self, isize):\n",
    "        super(ResnetClassifier1, self).__init__()\n",
    "        rsize = isize * 3\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(isize, rsize),\n",
    "            nn.ReLU(inplace=True),\n",
    "            ResnetLayerV1(rsize, nn.ReLU(inplace=True), nn.ReLU(inplace=True)),\n",
    "            ResnetLayerV1(rsize, nn.ReLU(inplace=True), nn.ReLU(inplace=True)),\n",
    "            ResnetLayerV1(rsize, nn.ReLU(inplace=True), nn.ReLU(inplace=True)),\n",
    "            nn.Linear(rsize, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_modelfile = '../models/js_resnet_model1.pt'\n",
    "resnet_model = ResnetClassifier1(num_feature_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_model = resnet_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = JSClassificationDataset(train_file)\n",
    "train_loader = data.DataLoader(trainset, **loader_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.0001\n",
    "total_epochs = 10\n",
    "optimizer = optim.Adam(resnet_model.parameters(recurse=True), lr=learning_rate)\n",
    "loss = nn.BCELoss()\n",
    "collector = EpochLossCollector(default_batch_size, 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, 2390400/2390491: 0.6810844540596008\n",
      "Epoch 1, 2390400/2390491: 0.6916476488113403\n",
      "Epoch 2, 2390400/2390491: 0.705119252204895\n",
      "Epoch 3, 2390400/2390491: 0.617253303527832\n",
      "Epoch 4, 2390400/2390491: 0.6355941891670227\n",
      "Epoch 5, 2390400/2390491: 0.6592046618461609\n",
      "Epoch 6, 2390400/2390491: 0.6671040654182434\n",
      "Epoch 7, 2390400/2390491: 0.6510292291641235\n",
      "Epoch 8, 2390400/2390491: 0.633138120174408\n",
      "Epoch 9, 2390400/2390491: 0.6383679509162903\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(total_epochs):\n",
    "    train(resnet_model, device, train_loader, optimizer, loss, epoch, collector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_validate(resnet_model, device, train_loader, loss, total_epochs, collector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(10, 0.004602857312198716, 0.6418012031837811)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collector.eval_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(resnet_model.dict(), resnet_modelfile)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
